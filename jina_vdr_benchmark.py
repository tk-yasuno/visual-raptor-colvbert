"""
JinaVDR (Visual Document Retrieval) ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµ±åˆ

éœ‡ç½é–¢é€£æ–‡æ›¸ã®æ¤œç´¢æ€§èƒ½è©•ä¾¡ç”¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
- æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¯¾å¿œ
- è¤‡é›‘ãªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ–‡æ›¸ï¼ˆã‚°ãƒ©ãƒ•ã€è¡¨ã€ã‚¹ã‚­ãƒ£ãƒ³ã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆï¼‰
- OCRãƒ†ã‚­ã‚¹ãƒˆä»˜ãç”»åƒï¼š500ï½1000æšè¦æ¨¡
- éœ‡ç½é–¢é€£æ–‡æ›¸ï¼ˆé¿é›£æ‰€ãƒãƒƒãƒ—ã€å¾©æ—§è¨ˆç”»ã€è¡Œæ”¿é€šçŸ¥ãªã©ï¼‰

Reference: jina-ai/jina-vdr
"""

import os
import json
import random
import numpy as np
from typing import List, Dict, Tuple, Optional, Any
from pathlib import Path
import urllib.request
import zipfile
from dataclasses import dataclass
import pandas as pd
from PIL import Image
import torch
from transformers import AutoTokenizer, AutoModel
import time

from visual_raptor_colbert import VisualDocument, VisualDocumentProcessor


@dataclass
class VDRQuery:
    """VDRã‚¯ã‚¨ãƒª"""
    query_id: str
    text: str
    language: str = "ja"
    category: str = "disaster"
    difficulty: str = "medium"


@dataclass
class VDRDocument:
    """VDRæ–‡æ›¸"""
    doc_id: str
    image_path: str
    text_content: str
    category: str
    subcategory: str
    metadata: Dict


@dataclass
class VDRRelevanceJudgment:
    """é–¢é€£æ€§åˆ¤å®š"""
    query_id: str
    doc_id: str
    relevance: int  # 0: ç„¡é–¢é€£, 1: é–¢é€£, 2: é«˜é–¢é€£


class JinaVDRBenchmark:
    """
    JinaVDR ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç®¡ç†ã‚¯ãƒ©ã‚¹
    
    éœ‡ç½é–¢é€£æ–‡æ›¸ã®æ¤œç´¢æ€§èƒ½è©•ä¾¡
    """
    
    def __init__(
        self,
        data_dir: str = "data/jina_vdr",
        language: str = "ja",
        dataset_size: str = "small"  # small: 500, medium: 1000, large: 2000+
    ):
        self.data_dir = Path(data_dir)
        self.language = language
        self.dataset_size = dataset_size
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
        self.images_dir = self.data_dir / "images"
        self.queries_dir = self.data_dir / "queries"
        self.annotations_dir = self.data_dir / "annotations"
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
        self.queries: List[VDRQuery] = []
        self.documents: List[VDRDocument] = []
        self.relevance_judgments: List[VDRRelevanceJudgment] = []
        
        self._create_directories()
        print(f"ğŸ“Š JinaVDR Benchmark initialized")
        print(f"   Language: {language}")
        print(f"   Dataset size: {dataset_size}")
        print(f"   Data directory: {data_dir}")
    
    def _create_directories(self):
        """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.images_dir.mkdir(exist_ok=True)
        self.queries_dir.mkdir(exist_ok=True)
        self.annotations_dir.mkdir(exist_ok=True)
    
    def generate_disaster_queries(self, num_queries: int = 50) -> List[VDRQuery]:
        """ç½å®³é–¢é€£ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ"""
        disaster_query_templates = [
            # é¿é›£ãƒ»å®‰å…¨
            ("é¿é›£æ‰€ã®å ´æ‰€ã‚’æ•™ãˆã¦ãã ã•ã„", "evacuation", "easy"),
            ("ç·Šæ€¥é¿é›£çµŒè·¯ã¯ã©ã“ã§ã™ã‹", "evacuation", "easy"),
            ("å®‰å…¨ãªé¿é›£å ´æ‰€ã¯ã‚ã‚Šã¾ã™ã‹", "evacuation", "easy"),
            ("æ´¥æ³¢é¿é›£ãƒ“ãƒ«ã®ä½ç½®", "evacuation", "medium"),
            ("é¿é›£æ‰€ã®åå®¹äººæ•°", "evacuation", "medium"),
            
            # å¾©æ—§ãƒ»å¾©èˆˆ
            ("å¾©æ—§å·¥äº‹ã®é€²æ—çŠ¶æ³", "recovery", "medium"),
            ("ã‚¤ãƒ³ãƒ•ãƒ©å¾©æ—§è¨ˆç”»", "recovery", "hard"),
            ("ä»®è¨­ä½å®…ã®é…ç½®å›³", "recovery", "medium"),
            ("å¾©èˆˆã¾ã¡ã¥ãã‚Šè¨ˆç”»", "recovery", "hard"),
            ("é“è·¯å¾©æ—§ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«", "recovery", "medium"),
            
            # è¡Œæ”¿ãƒ»æƒ…å ±
            ("ç½å®³å¯¾ç­–æœ¬éƒ¨ã‹ã‚‰ã®é€šçŸ¥", "administration", "easy"),
            ("é¿é›£æŒ‡ç¤ºã®è©³ç´°", "administration", "easy"),
            ("æ”¯æ´ç‰©è³‡ã®é…å¸ƒå ´æ‰€", "administration", "medium"),
            ("è¢«å®³çŠ¶æ³ã®å ±å‘Šæ›¸", "administration", "medium"),
            ("å¾©èˆˆäºˆç®—ã®å†…è¨³", "administration", "hard"),
            
            # é˜²ç½æ•™è‚²
            ("é˜²ç½è¨“ç·´ã®æ‰‹é †", "education", "easy"),
            ("ç½å®³æ™‚ã®è¡Œå‹•æŒ‡é‡", "education", "easy"),
            ("æ´¥æ³¢ã®å±é™ºæ€§ã«ã¤ã„ã¦", "education", "medium"),
            ("åœ°éœ‡ç™ºç”Ÿæ™‚ã®å¯¾å¿œ", "education", "medium"),
            ("é˜²ç½ãƒãƒƒãƒ—ã®è¦‹æ–¹", "education", "medium"),
            
            # è¢«å®³ãƒ»çµ±è¨ˆ
            ("è¢«å®³ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿", "statistics", "medium"),
            ("äººçš„è¢«å®³ã®çŠ¶æ³", "statistics", "hard"),
            ("å»ºç‰©è¢«å®³ã®åˆ†æ", "statistics", "hard"),
            ("çµŒæ¸ˆçš„æå¤±ã®è©•ä¾¡", "statistics", "hard"),
            ("å¾©èˆˆé€²æ—ã®æŒ‡æ¨™", "statistics", "hard"),
        ]
        
        queries = []
        for i in range(num_queries):
            template = random.choice(disaster_query_templates)
            query = VDRQuery(
                query_id=f"query_{i:03d}",
                text=template[0],
                language=self.language,
                category=template[1],
                difficulty=template[2]
            )
            queries.append(query)
        
        self.queries = queries
        return queries
    
    def create_synthetic_documents(
        self,
        num_documents: int = 500,
        base_text_dir: str = None
    ) -> List[VDRDocument]:
        """åˆæˆæ–‡æ›¸ã‚’ä½œæˆ"""
        if base_text_dir is None:
            base_text_dir = str(Path(__file__).parent / "0_base_tsunami-lesson-rag")
        
        # ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        base_text = self._load_base_text_data(base_text_dir)
        
        # æ–‡æ›¸ã‚«ãƒ†ã‚´ãƒª
        doc_categories = {
            "evacuation_map": "é¿é›£ãƒãƒƒãƒ—",
            "recovery_plan": "å¾©æ—§è¨ˆç”»æ›¸",
            "admin_notice": "è¡Œæ”¿é€šçŸ¥",
            "damage_report": "è¢«å®³å ±å‘Šæ›¸",
            "education_material": "é˜²ç½æ•™è‚²è³‡æ–™",
            "statistics": "çµ±è¨ˆãƒ‡ãƒ¼ã‚¿",
            "infrastructure": "ã‚¤ãƒ³ãƒ•ãƒ©æƒ…å ±",
            "support_info": "æ”¯æ´æƒ…å ±"
        }
        
        documents = []
        visual_processor = VisualDocumentProcessor()
        
        for i in range(num_documents):
            # ã‚«ãƒ†ã‚´ãƒªã‚’ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
            category = random.choice(list(doc_categories.keys()))
            subcategory = doc_categories[category]
            
            # åˆæˆç”»åƒã‚’ç”Ÿæˆï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯å®Ÿéš›ã®ç”»åƒã‚’ä½¿ç”¨ï¼‰
            image_path = self._create_synthetic_image(
                category, i, subcategory
            )
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ
            text_content = self._generate_document_text(
                base_text, category, subcategory
            )
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            metadata = {
                "created_date": "2024-01-01",
                "source": "synthetic",
                "format": "image_with_text",
                "processing_method": "ocr_extracted"
            }
            
            doc = VDRDocument(
                doc_id=f"doc_{i:04d}",
                image_path=str(image_path),
                text_content=text_content,
                category=category,
                subcategory=subcategory,
                metadata=metadata
            )
            documents.append(doc)
        
        self.documents = documents
        print(f"âœ… Created {len(documents)} synthetic documents")
        return documents
    
    def _load_base_text_data(self, base_dir: str) -> str:
        """ãƒ™ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(Path(base_dir) / "tohoku_earthquake_data.txt", 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šåŸºæœ¬çš„ãªç½å®³é–¢é€£ãƒ†ã‚­ã‚¹ãƒˆ
            return """\næ±æ—¥æœ¬å¤§éœ‡ç½ã«ãŠã‘ã‚‹æ•™è¨“ã¨å¯¾å¿œ\n\n1. é¿é›£è¡Œå‹•\næ´¥æ³¢è­¦å ±ç™ºè¡¨æ™‚ã«ã¯ã€ç›´ã¡ã«é«˜å°ã¸ã®é¿é›£ãŒé‡è¦ã§ã‚ã‚‹ã€‚\né‡œçŸ³å¸‚ã§ã¯ã€Œæ´¥æ³¢ã¦ã‚“ã§ã‚“ã“ã€ã®æ•™ãˆã«ã‚ˆã‚Šå¤šãã®å‘½ãŒæ•‘ã‚ã‚ŒãŸã€‚\n\n2. æƒ…å ±ä¼é”\né˜²ç½è¡Œæ”¿ç„¡ç·šã€æºå¸¯é›»è©±ã®ç·Šæ€¥é€Ÿå ±ãƒ¡ãƒ¼ãƒ«ç­‰ã®æ´»ç”¨\nåœé›»æ™‚ã®æƒ…å ±åé›†æ‰‹æ®µã®ç¢ºä¿ãŒèª²é¡Œ\n\n3. é¿é›£æ‰€é‹å–¶\né¿é›£æ‰€ã®é‹å–¶ã«ã¯åœ°åŸŸä½æ°‘ã®å”åŠ›ãŒä¸å¯æ¬ \nè¦é…æ…®è€…ã¸ã®æ”¯æ´ä½“åˆ¶ã®æ§‹ç¯‰\n\n4. å¾©æ—§ãƒ»å¾©èˆˆ\nã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãƒ‘ãƒ¼ãƒˆæ–¹å¼ã«ã‚ˆã‚‹æ”¯æ´\nå‰µé€ çš„å¾©èˆˆã®ç†å¿µã«åŸºã¥ãå–ã‚Šçµ„ã¿
"""
    
    def _generate_document_text(self, base_text: str, category: str, subcategory: str) -> str:
        """æ–‡æ›¸ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
        # ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ãŸãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
        category_texts = {
            "evacuation_map": f"""\n{subcategory}\n\né¿é›£å ´æ‰€ï¼šâ—‹â—‹å°å­¦æ ¡ä½“è‚²é¤¨\nåå®¹äººæ•°ï¼š200å\næ‰€åœ¨åœ°ï¼šâ—‹â—‹å¸‚â—‹â—‹ç”º1-1-1\né€£çµ¡å…ˆï¼šXXX-XXX-XXXX\n\né¿é›£çµŒè·¯ï¼š\n- å›½é“â—‹å·ç·šã‚’åŒ—ä¸Š\n- â—‹â—‹æ©‹ã‚’æ¸¡ã‚‹\n- ä¿¡å·ã‚’å³æŠ˜\n\næ³¨æ„äº‹é …ï¼š\n- å¾’æ­©ã§ã®é¿é›£ã‚’æ¨å¥¨\n- ãƒšãƒƒãƒˆåŒä¼´å¯\n- é£Ÿæ–™ãƒ»æ°´ã¯3æ—¥åˆ†æŒå‚\n""",
            "recovery_plan": f"""\n{subcategory}\n\nå¾©æ—§è¨ˆç”»æ¦‚è¦\nå¯¾è±¡åœ°åŸŸï¼šâ—‹â—‹åœ°åŒº\næœŸé–“ï¼š2024å¹´4æœˆï½2025å¹´3æœˆ\n\nä¸»è¦é …ç›®ï¼š\n1. é“è·¯å¾©æ—§ï¼ˆâ—‹â—‹é“è·¯ä»–ï¼‰\n2. ä¸Šä¸‹æ°´é“å¾©æ—§\n3. é›»åŠ›ã‚¤ãƒ³ãƒ•ãƒ©å¾©æ—§\n4. é€šä¿¡è¨­å‚™å¾©æ—§\n\näºˆç®—ï¼šç·é¡â—‹â—‹å„„å††\né€²æ—ï¼šç¾åœ¨30%å®Œäº†\n""",
            "admin_notice": f"""\nè¡Œæ”¿ã‹ã‚‰ã®ãŠçŸ¥ã‚‰ã›\n\nä»¶åï¼š{subcategory}\nç™ºè¡Œæ—¥ï¼š2024å¹´1æœˆ15æ—¥\nç™ºè¡Œè€…ï¼šâ—‹â—‹å¸‚ç½å®³å¯¾ç­–æœ¬éƒ¨\n\nå¸‚æ°‘ã®çš†æ§˜ã¸\n\nâ—‹â—‹åœ°åŒºã«ãŠã‘ã‚‹å¾©æ—§ä½œæ¥­ã«ã¤ã„ã¦ä¸‹è¨˜ã®é€šã‚ŠãŠçŸ¥ã‚‰ã›ã„ãŸã—ã¾ã™ã€‚\n\nè©³ç´°ã¯å¸‚ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ã‚’ã”ç¢ºèªãã ã•ã„ã€‚\nå•ã„åˆã‚ã›å…ˆï¼šâ—‹â—‹å¸‚å½¹æ‰€ XXX-XXX-XXXX
"""
        }
        
        return category_texts.get(category, f"{subcategory}\
        \
        é–¢é€£æƒ…å ±ï¼š\
        {base_text[:500]}...")
    
    def _create_synthetic_image(
        self, 
        category: str, 
        index: int, 
        subcategory: str
    ) -> Path:
        """åˆæˆç”»åƒã‚’ä½œæˆ"""
        # ç°¡å˜ãªåˆæˆç”»åƒã‚’ä½œæˆï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã‚ˆã‚Šè¤‡é›‘ãªç”»åƒç”ŸæˆãŒå¿…è¦ï¼‰
        from PIL import Image, ImageDraw, ImageFont
        
        # ç”»åƒã‚µã‚¤ã‚ºã¨ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
        width, height = 800, 600
        image = Image.new('RGB', (width, height), 'white')
        draw = ImageDraw.Draw(image)
        
        # ãƒ•ã‚©ãƒ³ãƒˆï¼ˆã‚·ã‚¹ãƒ†ãƒ ã«ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
        try:
            font = ImageFont.truetype("arial.ttf", 20)
            title_font = ImageFont.truetype("arial.ttf", 30)
        except:
            font = ImageFont.load_default()
            title_font = ImageFont.load_default()
        
        # ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ãŸç”»åƒç”Ÿæˆ
        if category == "evacuation_map":
            # é¿é›£ãƒãƒƒãƒ—é¢¨
            draw.rectangle([50, 50, width-50, height-50], outline='black', width=2)
            draw.text((60, 60), "é¿é›£ãƒãƒƒãƒ—", fill='black', font=title_font)
            draw.text((60, 100), subcategory, fill='blue', font=font)
            
            # ç°¡å˜ãªåœ°å›³è¦ç´ 
            draw.rectangle([100, 150, 200, 200], fill='green', outline='black')
            draw.text((105, 165), "é¿é›£æ‰€", fill='white', font=font)
            
            draw.line([(250, 175), (400, 175)], fill='gray', width=3)
            draw.text((300, 180), "é¿é›£çµŒè·¯", fill='black', font=font)
            
        elif category == "recovery_plan":
            # å¾©æ—§è¨ˆç”»æ›¸é¢¨
            draw.rectangle([50, 50, width-50, height-50], outline='navy', width=3)
            draw.text((60, 60), "å¾©æ—§è¨ˆç”»æ›¸", fill='navy', font=title_font)
            draw.text((60, 100), subcategory, fill='black', font=font)
            
            # è¡¨é¢¨ã®è¦ç´ 
            for i in range(4):
                y = 150 + i * 40
                draw.rectangle([100, y, 600, y+30], outline='black')
                draw.text((110, y+5), f"é …ç›® {i+1}", fill='black', font=font)
        
        elif category == "admin_notice":
            # è¡Œæ”¿é€šçŸ¥é¢¨
            draw.rectangle([50, 50, width-50, height-50], outline='red', width=2)
            draw.text((60, 60), "è¡Œæ”¿é€šçŸ¥", fill='red', font=title_font)
            draw.text((60, 100), subcategory, fill='black', font=font)
            
            # é‡è¦ãƒãƒ¼ã‚¯
            draw.ellipse([width-150, 60, width-60, 120], fill='red')
            draw.text((width-140, 80), "é‡è¦", fill='white', font=font)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        image_path = self.images_dir / f"{category}_{index:04d}.png"
        image.save(image_path)
        
        return image_path
    
    def generate_relevance_judgments(
        self,
        num_judgments_per_query: int = 10
    ) -> List[VDRRelevanceJudgment]:
        """é–¢é€£æ€§åˆ¤å®šã‚’ç”Ÿæˆ"""
        judgments = []
        
        for query in self.queries:
            # ã‚¯ã‚¨ãƒªã‚«ãƒ†ã‚´ãƒªã«åŸºã¥ã„ã¦é–¢é€£æ–‡æ›¸ã‚’é¸æŠ
            relevant_docs = [doc for doc in self.documents 
                           if self._is_relevant(query.category, doc.category)]
            
            # é–¢é€£æ–‡æ›¸ã‹ã‚‰ä¸€éƒ¨ã‚’é¸æŠ
            selected_docs = random.sample(
                relevant_docs, 
                min(num_judgments_per_query, len(relevant_docs))
            )
            
            for doc in selected_docs:
                # é–¢é€£æ€§ã‚¹ã‚³ã‚¢ã‚’æ±ºå®š
                relevance = self._calculate_relevance(query, doc)
                
                judgment = VDRRelevanceJudgment(
                    query_id=query.query_id,
                    doc_id=doc.doc_id,
                    relevance=relevance
                )
                judgments.append(judgment)
        
        self.relevance_judgments = judgments
        print(f"âœ… Generated {len(judgments)} relevance judgments")
        return judgments
    
    def _is_relevant(self, query_category: str, doc_category: str) -> bool:
        """ã‚¯ã‚¨ãƒªã¨æ–‡æ›¸ã®é–¢é€£æ€§ã‚’åˆ¤å®š"""
        # ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ”ãƒ³ã‚°
        category_mapping = {
            "evacuation": ["evacuation_map", "admin_notice", "education_material"],
            "recovery": ["recovery_plan", "infrastructure", "statistics"],
            "administration": ["admin_notice", "damage_report", "support_info"],
            "education": ["education_material", "evacuation_map"],
            "statistics": ["statistics", "damage_report"]
        }
        
        return doc_category in category_mapping.get(query_category, [])
    
    def _calculate_relevance(self, query: VDRQuery, doc: VDRDocument) -> int:
        """é–¢é€£æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        # ç°¡å˜ãªãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯
        if query.category == doc.category:
            return random.choice([1, 2])  # é–¢é€£ã¾ãŸã¯é«˜é–¢é€£
        elif self._is_relevant(query.category, doc.category):
            return 1  # é–¢é€£
        else:
            return 0  # ç„¡é–¢é€£
    
    def save_benchmark_data(self):
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        # ã‚¯ã‚¨ãƒªä¿å­˜
        queries_data = [
            {
                "query_id": q.query_id,
                "text": q.text,
                "language": q.language,
                "category": q.category,
                "difficulty": q.difficulty
            }
            for q in self.queries
        ]
        
        with open(self.queries_dir / "queries.json", 'w', encoding='utf-8') as f:
            json.dump(queries_data, f, ensure_ascii=False, indent=2)
        
        # æ–‡æ›¸ä¿å­˜
        documents_data = [
            {
                "doc_id": d.doc_id,
                "image_path": d.image_path,
                "text_content": d.text_content,
                "category": d.category,
                "subcategory": d.subcategory,
                "metadata": d.metadata
            }
            for d in self.documents
        ]
        
        with open(self.annotations_dir / "documents.json", 'w', encoding='utf-8') as f:
            json.dump(documents_data, f, ensure_ascii=False, indent=2)
        
        # é–¢é€£æ€§åˆ¤å®šä¿å­˜
        judgments_data = [
            {
                "query_id": j.query_id,
                "doc_id": j.doc_id,
                "relevance": j.relevance
            }
            for j in self.relevance_judgments
        ]
        
        with open(self.annotations_dir / "relevance_judgments.json", 'w', encoding='utf-8') as f:
            json.dump(judgments_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… Benchmark data saved to {self.data_dir}")
    
    def load_benchmark_data(self):
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        # ã‚¯ã‚¨ãƒªèª­ã¿è¾¼ã¿
        queries_file = self.queries_dir / "queries.json"
        if queries_file.exists():
            with open(queries_file, 'r', encoding='utf-8') as f:
                queries_data = json.load(f)
            
            self.queries = [
                VDRQuery(**q) for q in queries_data
            ]
        
        # æ–‡æ›¸èª­ã¿è¾¼ã¿
        documents_file = self.annotations_dir / "documents.json"
        if documents_file.exists():
            with open(documents_file, 'r', encoding='utf-8') as f:
                documents_data = json.load(f)
            
            self.documents = [
                VDRDocument(**d) for d in documents_data
            ]
        
        # é–¢é€£æ€§åˆ¤å®šèª­ã¿è¾¼ã¿
        judgments_file = self.annotations_dir / "relevance_judgments.json"
        if judgments_file.exists():
            with open(judgments_file, 'r', encoding='utf-8') as f:
                judgments_data = json.load(f)
            
            self.relevance_judgments = [
                VDRRelevanceJudgment(**j) for j in judgments_data
            ]
        
        print(f"âœ… Benchmark data loaded from {self.data_dir}")
        print(f"   Queries: {len(self.queries)}")
        print(f"   Documents: {len(self.documents)}")
        print(f"   Judgments: {len(self.relevance_judgments)}")
    
    def get_benchmark_statistics(self) -> Dict[str, Any]:
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµ±è¨ˆã‚’å–å¾—"""
        stats = {
            "num_queries": len(self.queries),
            "num_documents": len(self.documents),
            "num_judgments": len(self.relevance_judgments),
            "query_categories": {},
            "document_categories": {},
            "relevance_distribution": {0: 0, 1: 0, 2: 0}
        }
        
        # ã‚¯ã‚¨ãƒªã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ
        for query in self.queries:
            stats["query_categories"][query.category] = \
                stats["query_categories"].get(query.category, 0) + 1
        
        # æ–‡æ›¸ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ
        for doc in self.documents:
            stats["document_categories"][doc.category] = \
                stats["document_categories"].get(doc.category, 0) + 1
        
        # é–¢é€£æ€§åˆ†å¸ƒ
        for judgment in self.relevance_judgments:
            stats["relevance_distribution"][judgment.relevance] += 1
        
        return stats


def create_jina_vdr_benchmark(
    data_dir: str = "data/jina_vdr",
    num_queries: int = 50,
    num_documents: int = 500,
    dataset_size: str = "small"
    ) -> JinaVDRBenchmark:
    """JinaVDRãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä½œæˆ"""
    print("="*80)
    print("Creating JinaVDR Benchmark for Disaster Document Retrieval")
    print("="*80)
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯åˆæœŸåŒ–
    benchmark = JinaVDRBenchmark(
        data_dir=data_dir,
        language="ja",
        dataset_size=dataset_size
    )
    
    # ã‚¯ã‚¨ãƒªç”Ÿæˆ
    print(f"\
    ğŸ” Generating {num_queries} queries...")
    benchmark.generate_disaster_queries(num_queries)
    
    # æ–‡æ›¸ç”Ÿæˆ
    print(f"\
    ğŸ“„ Creating {num_documents} synthetic documents...")
    benchmark.create_synthetic_documents(num_documents)
    
    # é–¢é€£æ€§åˆ¤å®šç”Ÿæˆ
    print(f"\
    ğŸ“Š Generating relevance judgments...")
    benchmark.generate_relevance_judgments()
    
    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    print(f"\
    ğŸ’¾ Saving benchmark data...")
    benchmark.save_benchmark_data()
    
    # çµ±è¨ˆè¡¨ç¤º
    stats = benchmark.get_benchmark_statistics()
    print(f"\
    ğŸ“ˆ Benchmark Statistics:")
    print(f"   Queries: {stats['num_queries']}")
    print(f"   Documents: {stats['num_documents']}")
    print(f"   Judgments: {stats['num_judgments']}")
    print(f"   Query categories: {list(stats['query_categories'].keys())}")
    print(f"   Document categories: {list(stats['document_categories'].keys())}")
    
    print(f"\nâœ… JinaVDR benchmark created successfully!")
    print(f"   Data directory: {data_dir}")
    
    return benchmark


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä½œæˆ
    benchmark = create_jina_vdr_benchmark(
        data_dir="data/jina_vdr_disaster",
        num_queries=50,
        num_documents=500,
        dataset_size="small"
    )
    
    print("\n" + "="*80)
    print("JinaVDR Benchmark Setup Complete")
    print("="*80)


class DisasterDocumentGenerator:
    """ç½å®³ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹ï¼ˆcompare_encoders.pyç”¨ï¼‰"""
    
    def __init__(self):
        self.disaster_types = [
            "earthquake", "tsunami", "flood", "typhoon", "landslide",
            "volcanic_eruption", "fire", "evacuation", "rescue", "recovery"
        ]
        self.locations = [
            "Tokyo", "Osaka", "Sendai", "Fukushima", "Kobe",
            "Nagoya", "Sapporo", "Hiroshima", "Kumamoto", "Iwate"
        ]
    
    def generate_disaster_queries(self, num_queries: int = 20) -> List[Dict]:
        """ç½å®³é–¢é€£ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ"""
        query_templates = [
            "é¿é›£æ‰€ã®å ´æ‰€ã‚’æ•™ãˆã¦ãã ã•ã„",
            "{}ã®è¢«å®³çŠ¶æ³ã«ã¤ã„ã¦",
            "{}åœ°åŸŸã®å¾©æ—§è¨ˆç”»ã¯ï¼Ÿ",
            "ç½å®³ç™ºç”Ÿæ™‚ã®ç·Šæ€¥é€£çµ¡å…ˆ",
            "{}ã§ã®æ•‘æ´ç‰©è³‡é…å¸ƒå ´æ‰€",
            "æ´¥æ³¢è­¦å ±ã®ç™ºä»¤çŠ¶æ³",
            "åœ°éœ‡ã®éœ‡åº¦åˆ†å¸ƒãƒãƒƒãƒ—",
            "é¿é›£çµŒè·¯ã®ç¢ºèªæ–¹æ³•",
            "{}ã®å®‰å¦æƒ…å ±ç¢ºèª",
            "ç½å®³æ”¯æ´ãƒœãƒ©ãƒ³ãƒ†ã‚£ã‚¢ã®å‹Ÿé›†"
        ]
        
        queries = []
        for i in range(num_queries):
            template = random.choice(query_templates)
            location = random.choice(self.locations)
            disaster_type = random.choice(self.disaster_types)
            
            if "{}" in template:
                query_text = template.format(location)
            else:
                query_text = template
            
            queries.append({
                'query_id': f"Q{i+1:03d}",
                'query': query_text,
                'disaster_type': disaster_type,
                'location': location
            })
        
        return queries
    
    def create_synthetic_documents(self, num_documents: int = 100) -> List[Dict]:
        """åˆæˆç½å®³ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ"""
        document_templates = [
            "ã€ç·Šæ€¥ã€‘{}ã§{}ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ä½æ°‘ã®çš†æ§˜ã¯ç›´ã¡ã«æŒ‡å®šé¿é›£æ‰€ã«é¿é›£ã—ã¦ãã ã•ã„ã€‚",
            "{}åœ°åŸŸã®å¾©æ—§ä½œæ¥­ãŒé€²ã‚“ã§ã„ã¾ã™ã€‚ç¾åœ¨ã€{}ã®è¢«å®³ãŒå ±å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚",
            "é¿é›£æ‰€ãƒãƒƒãƒ—ï¼š{}åœ°åŒºã®é¿é›£æ‰€ä¸€è¦§ã€‚æœ€å¯„ã‚Šã®é¿é›£æ‰€ã¯{}ã§ã™ã€‚",
            "{}ã«ãŠã‘ã‚‹{}ã®è¢«å®³çŠ¶æ³ï¼šå»ºç‰©å€’å£Šã€é“è·¯å¯¸æ–­ã€ãƒ©ã‚¤ãƒ•ãƒ©ã‚¤ãƒ³åœæ­¢ã€‚",
            "æ•‘æ´ç‰©è³‡é…å¸ƒã®ãŠçŸ¥ã‚‰ã›ï¼š{}åœ°åŸŸã§{}æ™‚ã‚ˆã‚Šé…å¸ƒã‚’é–‹å§‹ã—ã¾ã™ã€‚",
            "å®‰å¦æƒ…å ±ï¼š{}åœ°åŒºã®ä½æ°‘ã®çš†æ§˜ã®å®‰å¦ç¢ºèªã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚",
            "å¾©æ—§è¨ˆç”»ï¼š{}åœ°åŸŸã®{}å¾©æ—§ä½œæ¥­ã¯æ¥é€±ã‹ã‚‰é–‹å§‹äºˆå®šã§ã™ã€‚",
            "ãƒœãƒ©ãƒ³ãƒ†ã‚£ã‚¢å‹Ÿé›†ï¼š{}ã§ã®ç½å®³æ”¯æ´æ´»å‹•ã«ã”å”åŠ›ãã ã•ã„ã€‚",
            "æ°—è±¡è­¦å ±ï¼š{}åœ°æ–¹ã«{}è­¦å ±ãŒç™ºä»¤ã•ã‚Œã¾ã—ãŸã€‚å³é‡ã«è­¦æˆ’ã—ã¦ãã ã•ã„ã€‚",
            "é¿é›£æŒ‡ç¤ºè§£é™¤ï¼š{}åœ°åŒºã®é¿é›£æŒ‡ç¤ºãŒè§£é™¤ã•ã‚Œã¾ã—ãŸã€‚"
        ]
        
        documents = []
        for i in range(num_documents):
            template = random.choice(document_templates)
            location = random.choice(self.locations)
            disaster_type = random.choice(self.disaster_types)
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…å®¹ã‚’ç”Ÿæˆ
            content = template.format(location, disaster_type)
            
            # è¿½åŠ æƒ…å ±ã‚’ä»˜åŠ 
            additional_info = [
                f"ç™ºè¡¨æ™‚åˆ»: 2024å¹´{random.randint(1,12)}æœˆ{random.randint(1,28)}æ—¥ {random.randint(0,23)}æ™‚{random.randint(0,59)}åˆ†",
                f"å¯¾è±¡åœ°åŸŸ: {location}ãŠã‚ˆã³å‘¨è¾ºåœ°åŸŸ",
                f"é¿é›£è€…æ•°: ç´„{random.randint(100,10000)}å",
                f"è¢«å®³çŠ¶æ³: è©³ç´°èª¿æŸ»ä¸­",
                "å•ã„åˆã‚ã›: ç½å®³å¯¾ç­–æœ¬éƒ¨ 0120-XXX-XXX"
            ]
            
            content += "\n\n" + "\n".join(random.sample(additional_info, 3))
            
            documents.append({
                'doc_id': f"D{i+1:03d}",
                'title': f"{disaster_type.upper()} - {location}",
                'content': content,
                'disaster_type': disaster_type,
                'location': location,
                'timestamp': f"2024-{random.randint(1,12):02d}-{random.randint(1,28):02d}"
            })
        
        return documents


if __name__ == "__main__":
    main()