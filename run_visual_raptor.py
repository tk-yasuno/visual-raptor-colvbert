"""
Visual RAPTOR ColBERT å®Œå…¨å®Ÿè¡Œãƒ‡ãƒ¢
ColModernVBERT (SigLIP) ã‚’ä½¿ç”¨ã—ãŸç½å®³æ–‡æ›¸æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import sys
import time
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from visual_raptor_colbert import VisualRAPTORColBERT, VisualDocument
from langchain_ollama import OllamaEmbeddings, ChatOllama
from jina_vdr_benchmark import DisasterDocumentGenerator

print("=" * 80)
print("ğŸš€ Visual RAPTOR ColBERT - å®Œå…¨å®Ÿè¡Œãƒ‡ãƒ¢")
print("=" * 80)

# ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 1/8] å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™...")
output_dir = Path("data/visual_raptor_run")
images_dir = output_dir / "images"
images_dir.mkdir(parents=True, exist_ok=True)
print(f"âœ… {output_dir} æº–å‚™å®Œäº†")

# ã‚¹ãƒ†ãƒƒãƒ—2: Ollamaãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 2/8] Ollamaãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–...")
embeddings_model = OllamaEmbeddings(
    model="mxbai-embed-large",
    base_url="http://localhost:11434"
)

llm = ChatOllama(
    model="granite-code:8b",
    base_url="http://localhost:11434",
    temperature=0.0,
    request_timeout=600.0
)
print("âœ… Ollama mxbai-embed-large & granite-code:8b åˆæœŸåŒ–å®Œäº†")

# ã‚¹ãƒ†ãƒƒãƒ—3: ColModernVBERTåˆæœŸåŒ–
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 3/8] ColModernVBERT (SigLIP) åˆæœŸåŒ–...")
config = {
    'encoder_type': 'modern',
    'embedding_dim': 768,
    'use_cross_attention': True
}

visual_raptor = VisualRAPTORColBERT(
    embeddings_model=embeddings_model,
    llm=llm,
    use_modern_vbert=True,
    colbert_config=config
)
print("âœ… Visual RAPTOR ColBERT with SigLIP åˆæœŸåŒ–å®Œäº†")

# ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ†ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 4/8] ç½å®³é–¢é€£Visual Documentç”Ÿæˆ...")
doc_generator = DisasterDocumentGenerator()
documents = doc_generator.create_synthetic_documents(num_documents=20)

visual_documents = []
for i, doc in enumerate(documents):
    # ç”»åƒç”Ÿæˆ
    img = Image.new('RGB', (640, 480), color=(240, 240, 255))
    draw = ImageDraw.Draw(img)
    
    try:
        font_title = ImageFont.truetype("arial.ttf", 20)
        font_body = ImageFont.truetype("arial.ttf", 12)
    except:
        font_title = ImageFont.load_default()
        font_body = ImageFont.load_default()
    
    # ã‚¿ã‚¤ãƒˆãƒ«æç”»
    title = f"{doc['disaster_type'].upper()} - {doc['location']}"
    draw.text((20, 20), title[:60], fill=(0, 0, 100), font=font_title)
    
    # å†…å®¹æç”»ï¼ˆæ”¹è¡Œå‡¦ç†ï¼‰
    content_lines = doc['content'][:400].split('ã€‚')
    y_pos = 60
    for line in content_lines[:8]:
        if line.strip():
            draw.text((20, y_pos), line[:80], fill=(40, 40, 40), font=font_body)
            y_pos += 25
    
    # ä¿å­˜
    img_path = images_dir / f"disaster_{i:03d}.png"
    img.save(img_path)
    
    # VisualDocumentã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
    visual_doc = VisualDocument(
        image_path=str(img_path),
        text_content=doc['content'],
        metadata={
            'doc_id': doc['doc_id'],
            'title': doc['title'],
            'disaster_type': doc['disaster_type'],
            'location': doc['location']
        }
    )
    visual_documents.append(visual_doc)

print(f"âœ… {len(visual_documents)}å€‹ã®Visual Documentç”Ÿæˆå®Œäº†")

# ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 5/8] Visual Documentã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°...")
start_time = time.time()

encoded_docs = []
for i, vdoc in enumerate(visual_documents):
    try:
        image = Image.open(vdoc.image_path).convert('RGB')
        
        # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        embedding = visual_raptor.colbert_encoder.encode_multimodal(
            [vdoc.text_content[:500]],
            [image]
        )
        encoded_docs.append({
            'doc': vdoc,
            'embedding': embedding
        })
        
        if (i + 1) % 5 == 0:
            print(f"  é€²æ—: {i + 1}/{len(visual_documents)}")
    except Exception as e:
        print(f"  âš ï¸ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ {i} ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")

encoding_time = time.time() - start_time
print(f"âœ… {len(encoded_docs)}å€‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å®Œäº† ({encoding_time:.2f}ç§’)")

# ã‚¹ãƒ†ãƒƒãƒ—6: ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒªç”Ÿæˆ
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 6/8] æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆ...")
queries = doc_generator.generate_disaster_queries(num_queries=5)
print(f"âœ… {len(queries)}å€‹ã®ã‚¯ã‚¨ãƒªç”Ÿæˆ:")
for i, q in enumerate(queries, 1):
    print(f"  {i}. {q['query']}")

# ã‚¹ãƒ†ãƒƒãƒ—7: ã‚¯ã‚¨ãƒªæ¤œç´¢å®Ÿè¡Œ
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 7/8] ã‚¯ã‚¨ãƒªæ¤œç´¢å®Ÿè¡Œ...")
import torch
import numpy as np

for query_data in queries:
    query_text = query_data['query']
    print(f"\nğŸ” ã‚¯ã‚¨ãƒª: {query_text}")
    
    # ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    query_embedding = visual_raptor.colbert_encoder.encode_text([query_text])
    query_np = query_embedding.detach().cpu().numpy()
    
    # é¡ä¼¼åº¦è¨ˆç®—
    similarities = []
    for i, encoded_doc in enumerate(encoded_docs):
        doc_np = encoded_doc['embedding'].detach().cpu().numpy()
        
        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
        query_norm = query_np / (np.linalg.norm(query_np) + 1e-8)
        doc_norm = doc_np / (np.linalg.norm(doc_np) + 1e-8)
        sim = np.dot(query_norm.flatten(), doc_norm.flatten())
        
        similarities.append((i, sim))
    
    # Top-3å–å¾—
    similarities.sort(key=lambda x: x[1], reverse=True)
    top_3 = similarities[:3]
    
    print("  ğŸ“Š Top 3 çµæœ:")
    for rank, (doc_idx, sim) in enumerate(top_3, 1):
        doc = encoded_docs[doc_idx]['doc']
        print(f"    {rank}. [é¡ä¼¼åº¦: {sim:.4f}] {doc.metadata.get('title', 'N/A')}")
        print(f"       ã‚¿ã‚¤ãƒ—: {doc.metadata.get('disaster_type', 'N/A')}")
        print(f"       å ´æ‰€: {doc.metadata.get('location', 'N/A')}")

# ã‚¹ãƒ†ãƒƒãƒ—8: çµ±è¨ˆã‚µãƒãƒªãƒ¼
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 8/8] å®Ÿè¡Œã‚µãƒãƒªãƒ¼")
print("=" * 80)
print(f"ğŸ“Š Visual RAPTOR ColBERT å®Ÿè¡Œçµ±è¨ˆ")
print("=" * 80)
print(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼: ColModernVBERT (SigLIP)")
print(f"ç”Ÿæˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(visual_documents)}")
print(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æˆåŠŸæ•°: {len(encoded_docs)}")
print(f"æ¤œç´¢ã‚¯ã‚¨ãƒªæ•°: {len(queries)}")
print(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ™‚é–“: {encoding_time:.2f}ç§’")
print(f"å¹³å‡ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ™‚é–“: {encoding_time/len(visual_documents):.3f}ç§’/doc")
print(f"åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ: 768")
print(f"ã‚¯ãƒ­ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³: æœ‰åŠ¹")
print(f"ä½¿ç”¨GPU: {visual_raptor.colbert_encoder.device}")

print("\nğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
print(f"  ç”»åƒ: {images_dir} ({len(list(images_dir.glob('*.png')))}æš)")
print(f"  ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")

print("\n" + "=" * 80)
print("âœ… Visual RAPTOR ColBERT å®Ÿè¡Œå®Œäº†ï¼")
print("=" * 80)

print("\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
print("  1. data/visual_raptor_run/images/ ã§ç”Ÿæˆç”»åƒã‚’ç¢ºèª")
print("  2. æ¤œç´¢ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°ã‚’å¢—ã‚„ã™")
print("  3. ColVBERT (BLIP) ã¨ã®æ¯”è¼ƒã‚’å®Ÿè¡Œ")
print("  4. å®Ÿéš›ã®ç½å®³ç”»åƒãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ")
