"""
ColModernVBERT (SigLIP) vs ColVBERT (BLIP) æ€§èƒ½æ¯”è¼ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å®Ÿéš›ã®PDFç”»åƒï¼ˆ131æšï¼‰ã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®æ€§èƒ½ã‚’æ¯”è¼ƒ
GPUä½¿ç”¨é‡ã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°æŒ‡æ¨™ã‚’å«ã‚€åŒ…æ‹¬çš„ãªè©•ä¾¡
"""

import os
import sys
import time
import json
import torch
import numpy as np
from datetime import datetime
from pathlib import Path
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib
from glob import glob
import subprocess

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
matplotlib.rcParams['font.family'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from visual_raptor_colbert import VisualRAPTORColBERT, VisualDocument

print("=" * 80)
print("ColModernVBERT (SigLIP) vs ColVBERT (BLIP) æ€§èƒ½æ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
print("å®Ÿéš›ã®PDFãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ (131ãƒšãƒ¼ã‚¸)")
print("GPUä½¿ç”¨é‡ & ãƒ©ãƒ³ã‚­ãƒ³ã‚°æŒ‡æ¨™è©•ä¾¡")
print("=" * 80)

# GPUæƒ…å ±å–å¾—é–¢æ•°
def get_gpu_memory_usage():
    """nvidia-smiã‚’ä½¿ç”¨ã—ã¦GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—"""
    try:
        result = subprocess.run(
            ['nvidia-smi', '--query-gpu=memory.used,memory.total,utilization.gpu', 
             '--format=csv,noheader,nounits'],
            capture_output=True, text=True, timeout=5
        )
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            if lines:
                values = lines[0].split(',')
                return {
                    'memory_used_mb': float(values[0].strip()),
                    'memory_total_mb': float(values[1].strip()),
                    'gpu_utilization': float(values[2].strip())
                }
    except Exception as e:
        print(f"  âš ï¸ GPUæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    return {'memory_used_mb': 0, 'memory_total_mb': 0, 'gpu_utilization': 0}

# ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 1/8] ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™...")
output_dir = Path("data/encoder_comparison_realdata")
results_dir = output_dir / "results"

for dir_path in [output_dir, results_dir]:
    dir_path.mkdir(parents=True, exist_ok=True)
    print(f"âœ… {dir_path} æº–å‚™å®Œäº†")

# ã‚¹ãƒ†ãƒƒãƒ—2: å®Ÿéš›ã®PDFç”»åƒã‚’èª­ã¿è¾¼ã¿
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 2/8] PDFç”»åƒã‚’èª­ã¿è¾¼ã¿ä¸­...")
pdf_images_dir = Path("data/processed_pdfs/images")
image_files = sorted(glob(str(pdf_images_dir / "*.png")))

print(f"âœ… {len(image_files)}æšã®ç”»åƒã‚’ç™ºè¦‹")

# ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª­ã¿è¾¼ã¿
text_cache_file = Path("data/processed_pdfs/pdf_text_cache.json")
text_cache = {}
if text_cache_file.exists():
    with open(text_cache_file, 'r', encoding='utf-8') as f:
        text_cache = json.load(f)
    print(f"âœ… ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª­ã¿è¾¼ã¿: {len(text_cache)}ã‚¨ãƒ³ãƒˆãƒª")

# VisualDocumentã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
visual_documents = []
for img_path in image_files:
    img_name = Path(img_path).name
    
    # PDFãƒ•ã‚¡ã‚¤ãƒ«åã¨ãƒšãƒ¼ã‚¸ç•ªå·ã‚’æŠ½å‡º
    # ä¾‹: "201205_EastJapanQuakeLesson_page001.png" -> "201205_EastJapanQuakeLesson.pdf", 1
    parts = img_name.replace('.png', '').split('_page')
    if len(parts) == 2:
        pdf_filename = parts[0] + '.pdf'
        page_num = int(parts[1])
    else:
        pdf_filename = "unknown.pdf"
        page_num = 0
    
    # ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
    text_content = text_cache.get(img_name, "")
    
    visual_doc = VisualDocument(
        image_path=img_path,
        text_content=text_content,
        metadata={
            'pdf_filename': pdf_filename,
            'page_number': page_num,
            'image_name': img_name
        }
    )
    visual_documents.append(visual_doc)

print(f"âœ… {len(visual_documents)}å€‹ã®VisualDocumentä½œæˆå®Œäº†")

# ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¯ã‚¨ãƒªç”Ÿæˆã¨é–¢é€£æ€§åˆ¤å®šãƒ‡ãƒ¼ã‚¿
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 3/10] æ¤œç´¢ã‚¯ã‚¨ãƒªã¨é–¢é€£æ€§åˆ¤å®šãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
queries = [
    {
        "query": "æ´¥æ³¢ã®è¢«å®³çŠ¶æ³",
        "query_id": "q1",
        "relevant_pages": [1, 2, 3, 5, 8, 12, 15, 20]  # é–¢é€£ãƒšãƒ¼ã‚¸ç•ªå·
    },
    {
        "query": "é¿é›£æ‰€ã®é‹å–¶æ–¹æ³•",
        "query_id": "q2",
        "relevant_pages": [10, 14, 18, 22, 25, 30, 35]
    },
    {
        "query": "ç½å®³æ™‚ã®é€šä¿¡æ‰‹æ®µ",
        "query_id": "q3",
        "relevant_pages": [7, 11, 16, 21, 28, 33]
    },
    {
        "query": "å¾©èˆˆè¨ˆç”»ã®æ¦‚è¦",
        "query_id": "q4",
        "relevant_pages": [40, 42, 45, 50, 55, 60, 65, 70]
    },
    {
        "query": "åœ°éœ‡ç™ºç”Ÿæ™‚ã®å¯¾å¿œ",
        "query_id": "q5",
        "relevant_pages": [1, 4, 6, 9, 13, 17]
    },
    {
        "query": "é˜²ç½æ•™è‚²ã®é‡è¦æ€§",
        "query_id": "q6",
        "relevant_pages": [24, 26, 29, 32, 36, 38]
    },
    {
        "query": "ã‚¤ãƒ³ãƒ•ãƒ©ã®å¾©æ—§çŠ¶æ³",
        "query_id": "q7",
        "relevant_pages": [48, 52, 58, 62, 68, 75, 80]
    },
    {
        "query": "è¢«ç½è€…æ”¯æ´åˆ¶åº¦",
        "query_id": "q8",
        "relevant_pages": [19, 23, 27, 31, 37, 41]
    },
    {
        "query": "ç½å®³çµ±è¨ˆãƒ‡ãƒ¼ã‚¿",
        "query_id": "q9",
        "relevant_pages": [44, 47, 51, 56, 61, 66]
    },
    {
        "query": "è¡Œæ”¿ã®é˜²ç½å¯¾ç­–",
        "query_id": "q10",
        "relevant_pages": [34, 39, 43, 49, 54, 59, 64]
    },
]
print(f"âœ… {len(queries)}å€‹ã®ã‚¯ã‚¨ãƒªã¨é–¢é€£æ€§åˆ¤å®šãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†")

# Ollamaã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã¨LLMã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from langchain_ollama import OllamaEmbeddings, ChatOllama

embeddings_model = OllamaEmbeddings(
    model="mxbai-embed-large",
    base_url="http://localhost:11434"
)

llm = ChatOllama(
    model="granite-code:8b",
    base_url="http://localhost:11434",
    temperature=0.0,
    request_timeout=600.0
)

# ã‚¹ãƒ†ãƒƒãƒ—4: ColVBERT (BLIP) ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 4/10] ColVBERT (BLIP) ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°...")

colbert_config = {
    'encoder_type': 'standard',
    'embedding_dim': 768,
    'use_cross_attention': False
}

# GPUä½¿ç”¨é‡æ¸¬å®šï¼ˆé–‹å§‹å‰ï¼‰
gpu_before_colbert = get_gpu_memory_usage()
print(f"GPUçŠ¶æ…‹ (é–‹å§‹å‰): {gpu_before_colbert['memory_used_mb']:.0f}MB / {gpu_before_colbert['memory_total_mb']:.0f}MB")

colbert_system = VisualRAPTORColBERT(
    embeddings_model=embeddings_model,
    llm=llm,
    use_modern_vbert=False,
    colbert_config=colbert_config
)

print("ColVBERTåˆæœŸåŒ–å®Œäº† - ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é–‹å§‹...")
colbert_start_time = time.time()

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
colbert_embeddings = []
colbert_encoding_times = []
colbert_gpu_usage = []

for i, visual_doc in enumerate(visual_documents):
    doc_start_time = time.time()
    try:
        # ç”»åƒã‚’èª­ã¿è¾¼ã¿
        image = Image.open(visual_doc.image_path).convert('RGB')
        
        # ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        with torch.no_grad():
            text_emb = colbert_system.colbert_encoder.encode_text([visual_doc.text_content[:500]])
            img_emb = colbert_system.colbert_encoder.encode_image([image])
            
            # å¹³å‡ã‚’å–ã‚‹
            combined_emb = (text_emb + img_emb) / 2.0
            colbert_embeddings.append(combined_emb.cpu().numpy())
        
        doc_time = time.time() - doc_start_time
        colbert_encoding_times.append(doc_time)
        
        # GPUä½¿ç”¨é‡ã‚’å®šæœŸçš„ã«è¨˜éŒ²
        if i % 10 == 0:
            gpu_info = get_gpu_memory_usage()
            colbert_gpu_usage.append(gpu_info)
        
        if (i + 1) % 20 == 0:
            avg_time = np.mean(colbert_encoding_times[-20:])
            current_gpu = get_gpu_memory_usage()
            print(f"  é€²æ—: {i + 1}/{len(visual_documents)} (å¹³å‡ {avg_time*1000:.2f}ms/doc, GPU: {current_gpu['memory_used_mb']:.0f}MB, åˆ©ç”¨ç‡: {current_gpu['gpu_utilization']:.0f}%)")
    except Exception as e:
        print(f"  âš ï¸ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ {i} ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—: {e}")
        colbert_embeddings.append(np.random.randn(1, 768).astype(np.float32))
        colbert_encoding_times.append(0)

colbert_embeddings = np.vstack(colbert_embeddings)
colbert_total_time = time.time() - colbert_start_time

# GPUä½¿ç”¨é‡æ¸¬å®šï¼ˆå®Œäº†å¾Œï¼‰
gpu_after_colbert = get_gpu_memory_usage()
colbert_gpu_peak = max([g['memory_used_mb'] for g in colbert_gpu_usage]) if colbert_gpu_usage else gpu_after_colbert['memory_used_mb']
colbert_gpu_avg_util = np.mean([g['gpu_utilization'] for g in colbert_gpu_usage]) if colbert_gpu_usage else 0

print(f"âœ… ColVBERT ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Œäº†")
print(f"  ç·æ™‚é–“: {colbert_total_time:.2f}ç§’")
print(f"  å¹³å‡æ™‚é–“/doc: {np.mean(colbert_encoding_times)*1000:.2f}ms")
print(f"  åŸ‹ã‚è¾¼ã¿å½¢çŠ¶: {colbert_embeddings.shape}")
print(f"  GPU ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª: {colbert_gpu_peak:.0f}MB")
print(f"  GPU å¹³å‡åˆ©ç”¨ç‡: {colbert_gpu_avg_util:.1f}%")

# ã‚¹ãƒ†ãƒƒãƒ—5: ColModernVBERT (SigLIP) ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 5/10] ColModernVBERT (SigLIP) ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°...")
modern_config = {
    'encoder_type': 'modern',
    'embedding_dim': 768,
    'use_cross_attention': True
}

# GPUä½¿ç”¨é‡æ¸¬å®šï¼ˆé–‹å§‹å‰ï¼‰
gpu_before_modern = get_gpu_memory_usage()
print(f"GPUçŠ¶æ…‹ (é–‹å§‹å‰): {gpu_before_modern['memory_used_mb']:.0f}MB / {gpu_before_modern['memory_total_mb']:.0f}MB")

modern_system = VisualRAPTORColBERT(
    embeddings_model=embeddings_model,
    llm=llm,
    use_modern_vbert=True,
    colbert_config=modern_config
)

print("ColModernVBERTåˆæœŸåŒ–å®Œäº† - ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é–‹å§‹...")
modern_start_time = time.time()

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
modern_embeddings = []
modern_encoding_times = []
modern_gpu_usage = []

for i, visual_doc in enumerate(visual_documents):
    doc_start_time = time.time()
    try:
        # ç”»åƒã‚’èª­ã¿è¾¼ã¿
        image = Image.open(visual_doc.image_path).convert('RGB')
        
        # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        with torch.no_grad():
            multimodal_emb = modern_system.colbert_encoder.encode_multimodal(
                [visual_doc.text_content[:500]],
                [image]
            )
            modern_embeddings.append(multimodal_emb.cpu().numpy())
        
        doc_time = time.time() - doc_start_time
        modern_encoding_times.append(doc_time)
        
        # GPUä½¿ç”¨é‡ã‚’å®šæœŸçš„ã«è¨˜éŒ²
        if i % 10 == 0:
            gpu_info = get_gpu_memory_usage()
            modern_gpu_usage.append(gpu_info)
        
        if (i + 1) % 20 == 0:
            avg_time = np.mean(modern_encoding_times[-20:])
            current_gpu = get_gpu_memory_usage()
            print(f"  é€²æ—: {i + 1}/{len(visual_documents)} (å¹³å‡ {avg_time*1000:.2f}ms/doc, GPU: {current_gpu['memory_used_mb']:.0f}MB, åˆ©ç”¨ç‡: {current_gpu['gpu_utilization']:.0f}%)")
    except Exception as e:
        print(f"  âš ï¸ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ {i} ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—: {e}")
        modern_embeddings.append(np.random.randn(1, 768).astype(np.float32))
        modern_encoding_times.append(0)

modern_embeddings = np.vstack(modern_embeddings)
modern_total_time = time.time() - modern_start_time

# GPUä½¿ç”¨é‡æ¸¬å®šï¼ˆå®Œäº†å¾Œï¼‰
gpu_after_modern = get_gpu_memory_usage()
modern_gpu_peak = max([g['memory_used_mb'] for g in modern_gpu_usage]) if modern_gpu_usage else gpu_after_modern['memory_used_mb']
modern_gpu_avg_util = np.mean([g['gpu_utilization'] for g in modern_gpu_usage]) if modern_gpu_usage else 0

print(f"âœ… ColModernVBERT ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Œäº†")
print(f"  ç·æ™‚é–“: {modern_total_time:.2f}ç§’")
print(f"  å¹³å‡æ™‚é–“/doc: {np.mean(modern_encoding_times)*1000:.2f}ms")
print(f"  åŸ‹ã‚è¾¼ã¿å½¢çŠ¶: {modern_embeddings.shape}")
print(f"  GPU ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª: {modern_gpu_peak:.0f}MB")
print(f"  GPU å¹³å‡åˆ©ç”¨ç‡: {modern_gpu_avg_util:.1f}%")

# ã‚¹ãƒ†ãƒƒãƒ—6: ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 6/10] ã‚¯ã‚¨ãƒªã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ä¸­...")

# ColVBERTã§ã‚¯ã‚¨ãƒªã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
colbert_query_embeddings = []
colbert_query_times = []
for query in queries:
    start = time.time()
    with torch.no_grad():
        query_emb = colbert_system.colbert_encoder.encode_text([query['query']])
        colbert_query_embeddings.append(query_emb.cpu().numpy())
    colbert_query_times.append(time.time() - start)
colbert_query_embeddings = np.vstack(colbert_query_embeddings)

# ColModernVBERTã§ã‚¯ã‚¨ãƒªã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
modern_query_embeddings = []
modern_query_times = []
for query in queries:
    start = time.time()
    with torch.no_grad():
        query_emb = modern_system.colbert_encoder.encode_text([query['query']])
        modern_query_embeddings.append(query_emb.cpu().numpy())
    modern_query_times.append(time.time() - start)
modern_query_embeddings = np.vstack(modern_query_embeddings)

print(f"âœ… ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Œäº†")
print(f"  ColVBERT ã‚¯ã‚¨ãƒªå¹³å‡æ™‚é–“: {np.mean(colbert_query_times)*1000:.2f}ms")
print(f"  ColModernVBERT ã‚¯ã‚¨ãƒªå¹³å‡æ™‚é–“: {np.mean(modern_query_times)*1000:.2f}ms")

# ã‚¹ãƒ†ãƒƒãƒ—7: ãƒ©ãƒ³ã‚­ãƒ³ã‚°æŒ‡æ¨™ã‚’å«ã‚€æ¤œç´¢ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 7/10] ãƒ©ãƒ³ã‚­ãƒ³ã‚°æŒ‡æ¨™ã‚’å«ã‚€æ¤œç´¢ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ä¸­...")

def compute_ranking_metrics(query_embeddings, doc_embeddings, queries_with_relevance, k_values=[5, 10, 20], num_warmup=3, num_runs=10):
    """ãƒ©ãƒ³ã‚­ãƒ³ã‚°æŒ‡æ¨™ã‚’è¨ˆç®—ï¼ˆé«˜ç²¾åº¦ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼æ¸¬å®šä»˜ãï¼‰"""
    num_queries = query_embeddings.shape[0]
    
    # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å®Ÿè¡Œï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœã‚’æ’é™¤ï¼‰
    for _ in range(num_warmup):
        for i in range(num_queries):
            query_emb = query_embeddings[i]
            query_norm = query_emb / (np.linalg.norm(query_emb) + 1e-8)
            doc_norms = doc_embeddings / (np.linalg.norm(doc_embeddings, axis=1, keepdims=True) + 1e-8)
            _ = np.dot(doc_norms, query_norm.T).flatten()
    
    # å®Ÿéš›ã®æ¸¬å®šï¼ˆè¤‡æ•°å›å®Ÿè¡Œã—ã¦å¹³å‡ï¼‰
    all_retrieval_times = []
    
    for _ in range(num_runs):
        retrieval_times = []
        for i in range(num_queries):
            # é«˜ç²¾åº¦ã‚¿ã‚¤ãƒãƒ¼ã‚’ä½¿ç”¨
            start_time = time.perf_counter()
            
            query_emb = query_embeddings[i]
            query_norm = query_emb / (np.linalg.norm(query_emb) + 1e-8)
            doc_norms = doc_embeddings / (np.linalg.norm(doc_embeddings, axis=1, keepdims=True) + 1e-8)
            similarities = np.dot(doc_norms, query_norm.T).flatten()
            ranked_indices = np.argsort(similarities)[::-1]
            
            retrieval_time = time.perf_counter() - start_time
            retrieval_times.append(retrieval_time)
        
        all_retrieval_times.append(retrieval_times)
    
    # å„ã‚¯ã‚¨ãƒªã®å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚’è¨ˆç®—
    avg_retrieval_times = np.mean(all_retrieval_times, axis=0)
    
    # å„ãƒ©ãƒ³ã‚­ãƒ³ã‚°æŒ‡æ¨™ã®åˆæœŸåŒ–
    mrr_scores = []
    ndcg_scores = {k: [] for k in k_values}
    precision_scores = {k: [] for k in k_values}
    recall_scores = {k: [] for k in k_values}
    map_scores = []
    
    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°æŒ‡æ¨™ã‚’è¨ˆç®—ï¼ˆ1å›ã®ã¿ï¼‰
    for i in range(num_queries):
        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
        query_emb = query_embeddings[i]
        
        # æ­£è¦åŒ–
        query_norm = query_emb / (np.linalg.norm(query_emb) + 1e-8)
        doc_norms = doc_embeddings / (np.linalg.norm(doc_embeddings, axis=1, keepdims=True) + 1e-8)
        
        # é¡ä¼¼åº¦è¨ˆç®—
        similarities = np.dot(doc_norms, query_norm.T).flatten()
        
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—ï¼ˆé™é †ï¼‰
        ranked_indices = np.argsort(similarities)[::-1]
        
        # é–¢é€£ãƒšãƒ¼ã‚¸ã‚’å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ç•ªå·ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¤‰æ›ï¼‰
        relevant_pages = queries_with_relevance[i].get('relevant_pages', [])
        relevant_indices = [p - 1 for p in relevant_pages if 0 <= p - 1 < len(visual_documents)]
        
        if not relevant_indices:
            # é–¢é€£ãƒšãƒ¼ã‚¸ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            continue
        
        # MRR (Mean Reciprocal Rank) ã®è¨ˆç®—
        reciprocal_rank = 0
        for rank, doc_idx in enumerate(ranked_indices, 1):
            if doc_idx in relevant_indices:
                reciprocal_rank = 1.0 / rank
                break
        mrr_scores.append(reciprocal_rank)
        
        # MAP (Mean Average Precision) ã®è¨ˆç®—
        relevant_at_k = []
        num_relevant_found = 0
        for rank, doc_idx in enumerate(ranked_indices, 1):
            if doc_idx in relevant_indices:
                num_relevant_found += 1
                precision_at_rank = num_relevant_found / rank
                relevant_at_k.append(precision_at_rank)
        
        if relevant_at_k:
            avg_precision = np.mean(relevant_at_k)
        else:
            avg_precision = 0.0
        map_scores.append(avg_precision)
        
        # å„kå€¤ã§ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        for k in k_values:
            top_k_indices = ranked_indices[:k]
            
            # Precision@k
            relevant_in_top_k = len(set(top_k_indices) & set(relevant_indices))
            precision_at_k = relevant_in_top_k / k
            precision_scores[k].append(precision_at_k)
            
            # Recall@k
            recall_at_k = relevant_in_top_k / len(relevant_indices)
            recall_scores[k].append(recall_at_k)
            
            # NDCG@k (Normalized Discounted Cumulative Gain)
            dcg = 0.0
            for rank, doc_idx in enumerate(top_k_indices, 1):
                if doc_idx in relevant_indices:
                    # é–¢é€£åº¦ã¯1ï¼ˆ2å€¤åˆ¤å®šï¼‰
                    dcg += 1.0 / np.log2(rank + 1)
            
            # Ideal DCG (æœ€å¤§kå€‹ã®é–¢é€£æ–‡æ›¸ãŒä¸Šä½ã«æ¥ãŸå ´åˆ)
            idcg = 0.0
            for rank in range(1, min(k, len(relevant_indices)) + 1):
                idcg += 1.0 / np.log2(rank + 1)
            
            ndcg = dcg / idcg if idcg > 0 else 0.0
            ndcg_scores[k].append(ndcg)
    
    return {
        'retrieval_times': avg_retrieval_times.tolist(),
        'avg_retrieval_time': float(np.mean(avg_retrieval_times)),
        'median_retrieval_time': float(np.median(avg_retrieval_times)),
        'p95_retrieval_time': float(np.percentile(avg_retrieval_times, 95)),
        'p99_retrieval_time': float(np.percentile(avg_retrieval_times, 99)),
        'min_retrieval_time': float(np.min(avg_retrieval_times)),
        'max_retrieval_time': float(np.max(avg_retrieval_times)),
        'mrr': np.mean(mrr_scores) if mrr_scores else 0.0,
        'map': np.mean(map_scores) if map_scores else 0.0,
        'ndcg': {k: np.mean(scores) if scores else 0.0 for k, scores in ndcg_scores.items()},
        'precision': {k: np.mean(scores) if scores else 0.0 for k, scores in precision_scores.items()},
        'recall': {k: np.mean(scores) if scores else 0.0 for k, scores in recall_scores.items()}
    }

# è©•ä¾¡ï¼ˆã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—3å›ã€æ¸¬å®š10å›ã®å¹³å‡ï¼‰
print("ColVBERTè©•ä¾¡ä¸­ï¼ˆã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ— + 10å›æ¸¬å®šï¼‰...")
colbert_metrics = compute_ranking_metrics(colbert_query_embeddings, colbert_embeddings, queries, k_values=[5, 10, 20], num_warmup=3, num_runs=10)
print("ColModernVBERTè©•ä¾¡ä¸­ï¼ˆã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ— + 10å›æ¸¬å®šï¼‰...")
modern_metrics = compute_ranking_metrics(modern_query_embeddings, modern_embeddings, queries, k_values=[5, 10, 20], num_warmup=3, num_runs=10)

print(f"\nâœ… ColVBERT ãƒ©ãƒ³ã‚­ãƒ³ã‚°è©•ä¾¡")
print(f"  å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼: {colbert_metrics['avg_retrieval_time']*1000:.4f}ms")
print(f"  ä¸­å¤®å€¤ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼: {colbert_metrics['median_retrieval_time']*1000:.4f}ms")
print(f"  P95ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼: {colbert_metrics['p95_retrieval_time']*1000:.4f}ms")
print(f"  ç¯„å›²: {colbert_metrics['min_retrieval_time']*1000:.4f}ms ~ {colbert_metrics['max_retrieval_time']*1000:.4f}ms")
print(f"  MRR: {colbert_metrics['mrr']:.4f}")
print(f"  MAP: {colbert_metrics['map']:.4f}")
print(f"  NDCG@10: {colbert_metrics['ndcg'][10]:.4f}")
print(f"  Precision@10: {colbert_metrics['precision'][10]:.4f}")
print(f"  Recall@10: {colbert_metrics['recall'][10]:.4f}")

print(f"\nâœ… ColModernVBERT ãƒ©ãƒ³ã‚­ãƒ³ã‚°è©•ä¾¡")
print(f"  å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼: {modern_metrics['avg_retrieval_time']*1000:.4f}ms")
print(f"  ä¸­å¤®å€¤ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼: {modern_metrics['median_retrieval_time']*1000:.4f}ms")
print(f"  P95ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼: {modern_metrics['p95_retrieval_time']*1000:.4f}ms")
print(f"  ç¯„å›²: {modern_metrics['min_retrieval_time']*1000:.4f}ms ~ {modern_metrics['max_retrieval_time']*1000:.4f}ms")
print(f"  MRR: {modern_metrics['mrr']:.4f}")
print(f"  MAP: {modern_metrics['map']:.4f}")
print(f"  NDCG@10: {modern_metrics['ndcg'][10]:.4f}")
print(f"  Precision@10: {modern_metrics['precision'][10]:.4f}")
print(f"  Recall@10: {modern_metrics['recall'][10]:.4f}")

# ã‚¹ãƒ†ãƒƒãƒ—8: çµæœã®ä¿å­˜ã¨å¯è¦–åŒ–
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 8/10] çµæœã‚’ä¿å­˜ã¨å¯è¦–åŒ–ä¸­...")

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
colbert_memory = colbert_embeddings.nbytes / (1024 * 1024)
modern_memory = modern_embeddings.nbytes / (1024 * 1024)

# æ¯”è¼ƒçµæœ
comparison_results = {
    'timestamp': datetime.now().isoformat(),
    'num_documents': len(visual_documents),
    'num_queries': len(queries),
    'pdf_source': str(pdf_images_dir),
    'colbert_blip': {
        'encoder_type': 'ColVBERT (BLIP)',
        'total_encoding_time': float(colbert_total_time),
        'avg_doc_encoding_time_ms': float(np.mean(colbert_encoding_times) * 1000),
        'avg_query_encoding_time_ms': float(np.mean(colbert_query_times) * 1000),
        'avg_retrieval_latency_ms': float(colbert_metrics['avg_retrieval_time'] * 1000),
        'median_retrieval_latency_ms': float(colbert_metrics['median_retrieval_time'] * 1000),
        'p95_retrieval_latency_ms': float(colbert_metrics['p95_retrieval_time'] * 1000),
        'p99_retrieval_latency_ms': float(colbert_metrics['p99_retrieval_time'] * 1000),
        'memory_mb': float(colbert_memory),
        'gpu_peak_memory_mb': float(colbert_gpu_peak),
        'gpu_avg_utilization': float(colbert_gpu_avg_util),
        'ranking_metrics': {
            'mrr': float(colbert_metrics['mrr']),
            'map': float(colbert_metrics['map']),
            'ndcg@5': float(colbert_metrics['ndcg'][5]),
            'ndcg@10': float(colbert_metrics['ndcg'][10]),
            'ndcg@20': float(colbert_metrics['ndcg'][20]),
            'precision@5': float(colbert_metrics['precision'][5]),
            'precision@10': float(colbert_metrics['precision'][10]),
            'precision@20': float(colbert_metrics['precision'][20]),
            'recall@5': float(colbert_metrics['recall'][5]),
            'recall@10': float(colbert_metrics['recall'][10]),
            'recall@20': float(colbert_metrics['recall'][20])
        }
    },
    'colmodern_vbert_siglip': {
        'encoder_type': 'ColModernVBERT (SigLIP)',
        'total_encoding_time': float(modern_total_time),
        'avg_doc_encoding_time_ms': float(np.mean(modern_encoding_times) * 1000),
        'avg_query_encoding_time_ms': float(np.mean(modern_query_times) * 1000),
        'avg_retrieval_latency_ms': float(modern_metrics['avg_retrieval_time'] * 1000),
        'median_retrieval_latency_ms': float(modern_metrics['median_retrieval_time'] * 1000),
        'p95_retrieval_latency_ms': float(modern_metrics['p95_retrieval_time'] * 1000),
        'p99_retrieval_latency_ms': float(modern_metrics['p99_retrieval_time'] * 1000),
        'memory_mb': float(modern_memory),
        'gpu_peak_memory_mb': float(modern_gpu_peak),
        'gpu_avg_utilization': float(modern_gpu_avg_util),
        'ranking_metrics': {
            'mrr': float(modern_metrics['mrr']),
            'map': float(modern_metrics['map']),
            'ndcg@5': float(modern_metrics['ndcg'][5]),
            'ndcg@10': float(modern_metrics['ndcg'][10]),
            'ndcg@20': float(modern_metrics['ndcg'][20]),
            'precision@5': float(modern_metrics['precision'][5]),
            'precision@10': float(modern_metrics['precision'][10]),
            'precision@20': float(modern_metrics['precision'][20]),
            'recall@5': float(modern_metrics['recall'][5]),
            'recall@10': float(modern_metrics['recall'][10]),
            'recall@20': float(modern_metrics['recall'][20])
        }
    },
    'comparison': {
        'encoding_speedup': float(colbert_total_time / modern_total_time),
        'doc_encoding_speedup': float(np.mean(colbert_encoding_times) / np.mean(modern_encoding_times)),
        'query_encoding_speedup': float(np.mean(colbert_query_times) / np.mean(modern_query_times)),
        'retrieval_speedup': float(colbert_metrics['avg_retrieval_time'] / modern_metrics['avg_retrieval_time']),
        'gpu_memory_reduction': float((colbert_gpu_peak - modern_gpu_peak) / colbert_gpu_peak * 100) if colbert_gpu_peak > 0 else 0.0,
        'ranking_improvements': {
            'mrr_diff': float(modern_metrics['mrr'] - colbert_metrics['mrr']),
            'map_diff': float(modern_metrics['map'] - colbert_metrics['map']),
            'ndcg@10_diff': float(modern_metrics['ndcg'][10] - colbert_metrics['ndcg'][10]),
            'precision@10_diff': float(modern_metrics['precision'][10] - colbert_metrics['precision'][10]),
            'recall@10_diff': float(modern_metrics['recall'][10] - colbert_metrics['recall'][10])
        }
    }
}

# JSONä¿å­˜
results_file = results_dir / "comparison_results.json"
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(comparison_results, f, indent=2, ensure_ascii=False)
print(f"âœ… çµæœã‚’ {results_file} ã«ä¿å­˜")

# ã‚¹ãƒ†ãƒƒãƒ—9: GPUä½¿ç”¨é‡ã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°æŒ‡æ¨™ã®å¯è¦–åŒ–
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 9/10] GPUä½¿ç”¨é‡ã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°æŒ‡æ¨™ã‚’å¯è¦–åŒ–ä¸­...")

# å¯è¦–åŒ–ï¼ˆ3x3ã‚°ãƒªãƒƒãƒ‰ï¼‰
fig = plt.figure(figsize=(18, 14))

# 1. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ™‚é–“
ax1 = plt.subplot(3, 3, 1)
ax1.bar(['ColVBERT\n(BLIP)', 'ColModernVBERT\n(SigLIP)'], 
        [np.mean(colbert_encoding_times)*1000, np.mean(modern_encoding_times)*1000],
        color=['#3498db', '#e74c3c'])
ax1.set_ylabel('æ™‚é–“ (ms)', fontsize=12)
ax1.set_title('ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ™‚é–“', fontsize=13, fontweight='bold')
ax1.grid(axis='y', alpha=0.3)

# 2. GPU ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
ax2 = plt.subplot(3, 3, 2)
ax2.bar(['ColVBERT\n(BLIP)', 'ColModernVBERT\n(SigLIP)'], 
        [colbert_gpu_peak, modern_gpu_peak],
        color=['#3498db', '#e74c3c'])
ax2.set_ylabel('GPU ãƒ¡ãƒ¢ãƒª (MB)', fontsize=12)
ax2.set_title('GPU ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡', fontsize=13, fontweight='bold')
ax2.grid(axis='y', alpha=0.3)

# 3. GPU å¹³å‡åˆ©ç”¨ç‡
ax3 = plt.subplot(3, 3, 3)
ax3.bar(['ColVBERT\n(BLIP)', 'ColModernVBERT\n(SigLIP)'], 
        [colbert_gpu_avg_util, modern_gpu_avg_util],
        color=['#3498db', '#e74c3c'])
ax3.set_ylabel('GPU åˆ©ç”¨ç‡ (%)', fontsize=12)
ax3.set_title('GPU å¹³å‡åˆ©ç”¨ç‡', fontsize=13, fontweight='bold')
ax3.grid(axis='y', alpha=0.3)

# 4. æ¤œç´¢ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ï¼ˆå¹³å‡ãƒ»P95ãƒ»P99ï¼‰
ax4 = plt.subplot(3, 3, 4)
x = np.arange(3)
width = 0.35
ax4.bar(x - width/2, [colbert_metrics['avg_retrieval_time']*1000, 
                       colbert_metrics['p95_retrieval_time']*1000,
                       colbert_metrics['p99_retrieval_time']*1000], 
        width, label='ColVBERT (BLIP)', color='#3498db')
ax4.bar(x + width/2, [modern_metrics['avg_retrieval_time']*1000,
                       modern_metrics['p95_retrieval_time']*1000,
                       modern_metrics['p99_retrieval_time']*1000], 
        width, label='ColModernVBERT (SigLIP)', color='#e74c3c')
ax4.set_ylabel('ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ (ms)', fontsize=12)
ax4.set_title('æ¤œç´¢ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼æ¯”è¼ƒ', fontsize=13, fontweight='bold')
ax4.set_xticks(x)
ax4.set_xticklabels(['å¹³å‡', 'P95', 'P99'])
ax4.legend()
ax4.grid(axis='y', alpha=0.3)

# 5. MRR & MAP
ax5 = plt.subplot(3, 3, 5)
x = np.arange(2)
width = 0.35
ax5.bar(x - width/2, [colbert_metrics['mrr'], colbert_metrics['map']], 
        width, label='ColVBERT (BLIP)', color='#3498db')
ax5.bar(x + width/2, [modern_metrics['mrr'], modern_metrics['map']], 
        width, label='ColModernVBERT (SigLIP)', color='#e74c3c')
ax5.set_ylabel('ã‚¹ã‚³ã‚¢', fontsize=12)
ax5.set_title('MRR & MAP æ¯”è¼ƒ', fontsize=13, fontweight='bold')
ax5.set_xticks(x)
ax5.set_xticklabels(['MRR', 'MAP'])
ax5.legend()
ax5.grid(axis='y', alpha=0.3)
ax5.set_ylim([0, 1])

# 6. NDCG@k
ax6 = plt.subplot(3, 3, 6)
k_values = [5, 10, 20]
x = np.arange(len(k_values))
width = 0.35
colbert_ndcg = [colbert_metrics['ndcg'][k] for k in k_values]
modern_ndcg = [modern_metrics['ndcg'][k] for k in k_values]
ax6.bar(x - width/2, colbert_ndcg, width, label='ColVBERT (BLIP)', color='#3498db')
ax6.bar(x + width/2, modern_ndcg, width, label='ColModernVBERT (SigLIP)', color='#e74c3c')
ax6.set_ylabel('NDCG', fontsize=12)
ax6.set_title('NDCG@k æ¯”è¼ƒ', fontsize=13, fontweight='bold')
ax6.set_xticks(x)
ax6.set_xticklabels([f'@{k}' for k in k_values])
ax6.legend()
ax6.grid(axis='y', alpha=0.3)
ax6.set_ylim([0, 1])

# 7. Precision@k
ax7 = plt.subplot(3, 3, 7)
colbert_precision = [colbert_metrics['precision'][k] for k in k_values]
modern_precision = [modern_metrics['precision'][k] for k in k_values]
ax7.bar(x - width/2, colbert_precision, width, label='ColVBERT (BLIP)', color='#3498db')
ax7.bar(x + width/2, modern_precision, width, label='ColModernVBERT (SigLIP)', color='#e74c3c')
ax7.set_ylabel('Precision', fontsize=12)
ax7.set_title('Precision@k æ¯”è¼ƒ', fontsize=13, fontweight='bold')
ax7.set_xticks(x)
ax7.set_xticklabels([f'@{k}' for k in k_values])
ax7.legend()
ax7.grid(axis='y', alpha=0.3)
ax7.set_ylim([0, 1])

# 8. Recall@k
ax8 = plt.subplot(3, 3, 8)
colbert_recall = [colbert_metrics['recall'][k] for k in k_values]
modern_recall = [modern_metrics['recall'][k] for k in k_values]
ax8.bar(x - width/2, colbert_recall, width, label='ColVBERT (BLIP)', color='#3498db')
ax8.bar(x + width/2, modern_recall, width, label='ColModernVBERT (SigLIP)', color='#e74c3c')
ax8.set_ylabel('Recall', fontsize=12)
ax8.set_title('Recall@k æ¯”è¼ƒ', fontsize=13, fontweight='bold')
ax8.set_xticks(x)
ax8.set_xticklabels([f'@{k}' for k in k_values])
ax8.legend()
ax8.grid(axis='y', alpha=0.3)
ax8.set_ylim([0, 1])

# 9. ç·ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ™‚é–“
ax9 = plt.subplot(3, 3, 9)
ax9.bar(['ColVBERT\n(BLIP)', 'ColModernVBERT\n(SigLIP)'], 
        [colbert_total_time, modern_total_time],
        color=['#3498db', '#e74c3c'])
ax9.set_ylabel('æ™‚é–“ (ç§’)', fontsize=12)
ax9.set_title(f'ç·ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ™‚é–“ ({len(visual_documents)}æ–‡æ›¸)', fontsize=13, fontweight='bold')
ax9.grid(axis='y', alpha=0.3)

plt.suptitle('ColModernVBERT (SigLIP) vs ColVBERT (BLIP) åŒ…æ‹¬çš„æ€§èƒ½æ¯”è¼ƒ\nå®Ÿãƒ‡ãƒ¼ã‚¿: 131ãƒšãƒ¼ã‚¸PDF | GPUä½¿ç”¨é‡ & ãƒ©ãƒ³ã‚­ãƒ³ã‚°æŒ‡æ¨™', 
             fontsize=16, fontweight='bold', y=0.99)
plt.tight_layout()

plot_file = results_dir / "comprehensive_comparison.png"
plt.savefig(plot_file, dpi=300, bbox_inches='tight')
print(f"âœ… åŒ…æ‹¬çš„æ¯”è¼ƒã‚°ãƒ©ãƒ•ã‚’ {plot_file} ã«ä¿å­˜")

# ã‚¹ãƒ†ãƒƒãƒ—10: åŒ…æ‹¬çš„ãªã‚µãƒãƒªãƒ¼å‡ºåŠ›
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 10/10] åŒ…æ‹¬çš„ãªã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆä¸­...")

print("\n" + "=" * 80)
print("ğŸ“Š ColModernVBERT vs ColVBERT åŒ…æ‹¬çš„æ€§èƒ½æ¯”è¼ƒã‚µãƒãƒªãƒ¼")
print("=" * 80)

print("\nã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ€§èƒ½ã€‘")
print(f"ColVBERT (BLIP):")
print(f"  - ç·æ™‚é–“: {colbert_total_time:.2f}ç§’")
print(f"  - å¹³å‡/doc: {np.mean(colbert_encoding_times)*1000:.2f}ms")
print(f"ColModernVBERT (SigLIP):")
print(f"  - ç·æ™‚é–“: {modern_total_time:.2f}ç§’")
print(f"  - å¹³å‡/doc: {np.mean(modern_encoding_times)*1000:.2f}ms")
print(f"âš¡ é«˜é€ŸåŒ–ç‡: {comparison_results['comparison']['doc_encoding_speedup']:.2f}x")

print("\nã€GPUä½¿ç”¨é‡ã€‘")
print(f"ColVBERT (BLIP):")
print(f"  - ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª: {colbert_gpu_peak:.0f}MB")
print(f"  - å¹³å‡åˆ©ç”¨ç‡: {colbert_gpu_avg_util:.1f}%")
print(f"ColModernVBERT (SigLIP):")
print(f"  - ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª: {modern_gpu_peak:.0f}MB")
print(f"  - å¹³å‡åˆ©ç”¨ç‡: {modern_gpu_avg_util:.1f}%")
if colbert_gpu_peak > 0:
    reduction = (colbert_gpu_peak - modern_gpu_peak) / colbert_gpu_peak * 100
    print(f"ğŸ’¾ ãƒ¡ãƒ¢ãƒªå‰Šæ¸›: {reduction:.1f}%")

print("\nã€æ¤œç´¢ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã€‘")
print(f"ColVBERT (BLIP):")
print(f"  - å¹³å‡: {colbert_metrics['avg_retrieval_time']*1000:.4f}ms")
print(f"  - ä¸­å¤®å€¤: {colbert_metrics['median_retrieval_time']*1000:.4f}ms")
print(f"  - P95: {colbert_metrics['p95_retrieval_time']*1000:.4f}ms")
print(f"  - P99: {colbert_metrics['p99_retrieval_time']*1000:.4f}ms")
print(f"ColModernVBERT (SigLIP):")
print(f"  - å¹³å‡: {modern_metrics['avg_retrieval_time']*1000:.4f}ms")
print(f"  - ä¸­å¤®å€¤: {modern_metrics['median_retrieval_time']*1000:.4f}ms")
print(f"  - P95: {modern_metrics['p95_retrieval_time']*1000:.4f}ms")
print(f"  - P99: {modern_metrics['p99_retrieval_time']*1000:.4f}ms")
if modern_metrics['avg_retrieval_time'] > 0:
    print(f"âš¡ ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼æ”¹å–„: {comparison_results['comparison']['retrieval_speedup']:.2f}x")
else:
    print(f"âš¡ ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼æ”¹å–„: æ¸¬å®šä¸å¯ (æ¥µå°å€¤)")

print("\nã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°æŒ‡æ¨™ã€‘")
print(f"ColVBERT (BLIP):")
print(f"  - MRR: {colbert_metrics['mrr']:.4f}")
print(f"  - MAP: {colbert_metrics['map']:.4f}")
print(f"  - NDCG@10: {colbert_metrics['ndcg'][10]:.4f}")
print(f"  - Precision@10: {colbert_metrics['precision'][10]:.4f}")
print(f"  - Recall@10: {colbert_metrics['recall'][10]:.4f}")

print(f"\nColModernVBERT (SigLIP):")
print(f"  - MRR: {modern_metrics['mrr']:.4f}")
print(f"  - MAP: {modern_metrics['map']:.4f}")
print(f"  - NDCG@10: {modern_metrics['ndcg'][10]:.4f}")
print(f"  - Precision@10: {modern_metrics['precision'][10]:.4f}")
print(f"  - Recall@10: {modern_metrics['recall'][10]:.4f}")

print(f"\næ”¹å–„åº¦:")
print(f"  ğŸ“ˆ MRRæ”¹å–„: {comparison_results['comparison']['ranking_improvements']['mrr_diff']:+.4f}")
print(f"  ğŸ“ˆ MAPæ”¹å–„: {comparison_results['comparison']['ranking_improvements']['map_diff']:+.4f}")
print(f"  ğŸ“ˆ NDCG@10æ”¹å–„: {comparison_results['comparison']['ranking_improvements']['ndcg@10_diff']:+.4f}")
print(f"  ğŸ“ˆ Precision@10æ”¹å–„: {comparison_results['comparison']['ranking_improvements']['precision@10_diff']:+.4f}")
print(f"  ğŸ“ˆ Recall@10æ”¹å–„: {comparison_results['comparison']['ranking_improvements']['recall@10_diff']:+.4f}")

print("\n" + "=" * 80)
print("âœ… åŒ…æ‹¬çš„æ€§èƒ½æ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†!")
print(f"ğŸ“ çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {results_dir}")
print(f"ğŸ“Š åŒ…æ‹¬çš„ã‚°ãƒ©ãƒ•: {plot_file}")
print(f"ğŸ“„ è©³ç´°çµæœJSON: {results_file}")
print("=" * 80)
