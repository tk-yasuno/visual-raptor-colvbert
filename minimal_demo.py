"""
Minimal Quick Start Demo
ä¾å­˜é–¢ä¿‚ã‚’æœ€å°é™ã«ã—ãŸã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆãƒ‡ãƒ¢
"""

import os
import sys
import json
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List


def create_sample_data(output_dir: str = "data/minimal_demo") -> Dict[str, Any]:
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    print("ğŸ“Š Creating sample disaster document data...")
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    data_path = Path(output_dir)
    data_path.mkdir(parents=True, exist_ok=True)
    
    # ã‚µãƒ³ãƒ—ãƒ«ç½å®³æ–‡æ›¸ãƒ‡ãƒ¼ã‚¿
    sample_documents = [
        {
            "doc_id": "evac_map_001",
            "title": "é¿é›£ãƒãƒƒãƒ— - ä¸­å¤®åœ°åŒº",
            "content": "ä¸­å¤®åœ°åŒºã®é¿é›£æ‰€ï¼šä¸­å¤®å°å­¦æ ¡ä½“è‚²é¤¨ï¼ˆåå®¹äººæ•°200åï¼‰ã€é¿é›£çµŒè·¯ï¼šå›½é“1å·ç·šçµŒç”±",
            "category": "evacuation_map",
            "metadata": {
                "area": "ä¸­å¤®åœ°åŒº",
                "capacity": 200,
                "type": "evacuation"
            }
        },
        {
            "doc_id": "recovery_001",
            "title": "å¾©æ—§è¨ˆç”»æ›¸ - ã‚¤ãƒ³ãƒ•ãƒ©å¾©æ—§",
            "content": "é“è·¯å¾©æ—§ï¼šå›½é“1å·ç·šã®å¾©æ—§å®Œäº†ï¼ˆé€²æ—90%ï¼‰ã€æ°´é“å¾©æ—§ï¼šé…æ°´ç®¡ã®ä¿®å¾©ä½œæ¥­ä¸­ï¼ˆé€²æ—60%ï¼‰",
            "category": "recovery_plan",
            "metadata": {
                "progress": {"road": 90, "water": 60},
                "type": "infrastructure"
            }
        },
        {
            "doc_id": "admin_notice_001",
            "title": "è¡Œæ”¿é€šçŸ¥ - é¿é›£æŒ‡ç¤º",
            "content": "å°é¢¨æ¥è¿‘ã«ä¼´ã„ã€ä½åœ°åœ°åŸŸã«é¿é›£æŒ‡ç¤ºã‚’ç™ºä»¤ã€‚æŒ‡å®šé¿é›£æ‰€ï¼šä¸­å¤®å°å­¦æ ¡ã€å—éƒ¨å…¬æ°‘é¤¨",
            "category": "admin_notice",
            "metadata": {
                "urgency": "high",
                "affected_areas": ["ä½åœ°åœ°åŸŸ"],
                "type": "evacuation_order"
            }
        },
        {
            "doc_id": "damage_report_001",
            "title": "è¢«å®³å ±å‘Šæ›¸",
            "content": "äººçš„è¢«å®³ï¼šè² å‚·è€…5åã€å»ºç‰©è¢«å®³ï¼šå…¨å£Š3æ£Ÿã€åŠå£Š15æ£Ÿã€åœé›»ï¼š1,200ä¸–å¸¯",
            "category": "damage_report",
            "metadata": {
                "casualties": {"injured": 5},
                "buildings": {"destroyed": 3, "damaged": 15},
                "utilities": {"power_outage": 1200}
            }
        },
        {
            "doc_id": "support_info_001",
            "title": "æ”¯æ´ç‰©è³‡é…å¸ƒæƒ…å ±",
            "content": "é…å¸ƒå ´æ‰€ï¼šä¸­å¤®å°å­¦æ ¡ã€é…å¸ƒæ™‚é–“ï¼š9:00-17:00ã€é…å¸ƒç‰©è³‡ï¼šæ°´ã€é£Ÿæ–™ã€æ¯›å¸ƒ",
            "category": "support_info",
            "metadata": {
                "location": "ä¸­å¤®å°å­¦æ ¡",
                "hours": "9:00-17:00",
                "supplies": ["æ°´", "é£Ÿæ–™", "æ¯›å¸ƒ"]
            }
        }
    ]
    
    # ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒª
    sample_queries = [
        {
            "query_id": "q001",
            "text": "é¿é›£æ‰€ã®å ´æ‰€ã‚’æ•™ãˆã¦ãã ã•ã„",
            "category": "evacuation"
        },
        {
            "query_id": "q002", 
            "text": "å¾©æ—§å·¥äº‹ã®é€²æ—çŠ¶æ³ã¯ï¼Ÿ",
            "category": "recovery"
        },
        {
            "query_id": "q003",
            "text": "æ”¯æ´ç‰©è³‡ã®é…å¸ƒã«ã¤ã„ã¦",
            "category": "support"
        }
    ]
    
    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    documents_file = data_path / "sample_documents.json"
    with open(documents_file, 'w', encoding='utf-8') as f:
        json.dump(sample_documents, f, ensure_ascii=False, indent=2)
    
    queries_file = data_path / "sample_queries.json"
    with open(queries_file, 'w', encoding='utf-8') as f:
        json.dump(sample_queries, f, ensure_ascii=False, indent=2)
    
    print(f"   âœ… Created {len(sample_documents)} sample documents")
    print(f"   âœ… Created {len(sample_queries)} sample queries")
    print(f"   ğŸ“ Data saved to: {output_dir}")
    
    return {
        "documents": sample_documents,
        "queries": sample_queries,
        "output_dir": str(data_path)
    }


def simulate_search(documents: List[Dict], query: str) -> List[Dict]:
    """ç°¡å˜ãªæ¤œç´¢ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
    results = []
    query_lower = query.lower()
    
    for doc in documents:
        # ç°¡å˜ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
        content_lower = doc["content"].lower()
        title_lower = doc["title"].lower()
        
        score = 0.0
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã§ã®ãƒãƒƒãƒ
        for word in query_lower.split():
            if word in title_lower:
                score += 0.5
            if word in content_lower:
                score += 0.3
        
        # ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ
        if "é¿é›£" in query_lower and doc["category"] == "evacuation_map":
            score += 0.4
        elif "å¾©æ—§" in query_lower and doc["category"] == "recovery_plan":
            score += 0.4
        elif "æ”¯æ´" in query_lower and doc["category"] == "support_info":
            score += 0.4
        elif "è¢«å®³" in query_lower and doc["category"] == "damage_report":
            score += 0.4
        elif "é€šçŸ¥" in query_lower and doc["category"] == "admin_notice":
            score += 0.4
        
        if score > 0:
            results.append({
                "document": doc,
                "score": score,
                "relevance": "high" if score > 0.7 else "medium" if score > 0.4 else "low"
            })
    
    # ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
    results.sort(key=lambda x: x["score"], reverse=True)
    return results[:3]  # ä¸Šä½3ä»¶


def run_search_demo(data: Dict[str, Any]) -> Dict[str, Any]:
    """æ¤œç´¢ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ"""
    print("\nğŸ” Running search demonstration...")
    
    documents = data["documents"]
    queries = data["queries"]
    
    search_results = {}
    
    for query_info in queries:
        query_id = query_info["query_id"]
        query_text = query_info["text"]
        
        print(f"\n   Query: {query_text}")
        
        # æ¤œç´¢å®Ÿè¡Œ
        results = simulate_search(documents, query_text)
        
        # çµæœè¡¨ç¤º
        for i, result in enumerate(results, 1):
            doc = result["document"]
            score = result["score"]
            print(f"   [{i}] {doc['title']} (Score: {score:.2f})")
            print(f"       {doc['content'][:100]}...")
        
        search_results[query_id] = results
    
    return search_results


def calculate_demo_metrics(search_results: Dict[str, Any]) -> Dict[str, Any]:
    """ãƒ‡ãƒ¢ç”¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—"""
    total_queries = len(search_results)
    total_results = sum(len(results) for results in search_results.values())
    avg_results_per_query = total_results / total_queries if total_queries > 0 else 0
    
    # ç°¡å˜ãªå“è³ªè©•ä¾¡
    high_quality_results = 0
    for results in search_results.values():
        for result in results:
            if result["score"] > 0.7:
                high_quality_results += 1
    
    quality_ratio = high_quality_results / total_results if total_results > 0 else 0
    
    metrics = {
        "total_queries": total_queries,
        "total_results": total_results,
        "avg_results_per_query": avg_results_per_query,
        "high_quality_results": high_quality_results,
        "quality_ratio": quality_ratio,
        "demo_precision": quality_ratio  # ç°¡æ˜“çš„ãªç²¾åº¦æŒ‡æ¨™
    }
    
    return metrics


def save_demo_results(data: Dict[str, Any], search_results: Dict[str, Any], metrics: Dict[str, Any]):
    """ãƒ‡ãƒ¢çµæœã‚’ä¿å­˜"""
    output_dir = Path(data["output_dir"])
    
    demo_summary = {
        "demo_info": {
            "title": "Visual RAPTOR ColBERT - Minimal Demo",
            "description": "ç½å®³æ–‡æ›¸æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®åŸºæœ¬æ©Ÿèƒ½ãƒ‡ãƒ¢",
            "timestamp": datetime.now().isoformat(),
            "version": "1.0-minimal"
        },
        "data_summary": {
            "num_documents": len(data["documents"]),
            "num_queries": len(data["queries"]),
            "document_categories": list(set(doc["category"] for doc in data["documents"]))
        },
        "search_results": search_results,
        "metrics": metrics
    }
    
    results_file = output_dir / "demo_results.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(demo_summary, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ Demo results saved to: {results_file}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("="*80)
    print("ğŸš€ Visual RAPTOR ColBERT - Minimal Quick Start Demo")
    print("ç½å®³æ–‡æ›¸æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  - æœ€å°æ§‹æˆã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ")
    print("="*80)
    
    print("\nğŸ“ This is a minimal demonstration showing:")
    print("   - Basic disaster document data structure")
    print("   - Simple keyword-based search simulation")
    print("   - Performance metrics calculation")
    print("   - System component overview")
    
    try:
        # 1. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        print("\n" + "="*60)
        print("Step 1: Creating Sample Data")
        print("="*60)
        data = create_sample_data()
        
        # 2. æ¤œç´¢ãƒ‡ãƒ¢å®Ÿè¡Œ
        print("\n" + "="*60)
        print("Step 2: Search Demonstration")
        print("="*60)
        search_results = run_search_demo(data)
        
        # 3. ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        print("\n" + "="*60)
        print("Step 3: Performance Metrics")
        print("="*60)
        metrics = calculate_demo_metrics(search_results)
        
        print(f"   Total queries processed: {metrics['total_queries']}")
        print(f"   Average results per query: {metrics['avg_results_per_query']:.1f}")
        print(f"   High quality results: {metrics['high_quality_results']}")
        print(f"   Demo precision: {metrics['demo_precision']:.3f}")
        
        # 4. çµæœä¿å­˜
        save_demo_results(data, search_results, metrics)
        
        # 5. æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—æ¡ˆå†…
        print("\n" + "="*80)
        print("âœ… Minimal Demo Completed Successfully!")
        print("="*80)
        
        print("\nğŸ¯ What this demo showed:")
        print("   âœ“ Disaster document data structure")
        print("   âœ“ Basic search functionality")
        print("   âœ“ Performance evaluation")
        print("   âœ“ Results storage and analysis")
        
        print("\nğŸš€ Next steps for full system:")
        print("   1. Install full dependencies: pip install -r requirements.txt")
        print("   2. Set up Ollama: ollama pull mxbai-embed-large")
        print("   3. Run full demo: python quick_start_demo.py")
        print("   4. Explore visual document processing")
        print("   5. Try JinaVDR benchmarking")
        
        print(f"\nğŸ“ Generated files location: {data['output_dir']}")
        
    except Exception as e:
        print(f"\nâŒ Demo failed: {e}")
        print("This minimal demo should work without external dependencies.")


if __name__ == "__main__":
    main()