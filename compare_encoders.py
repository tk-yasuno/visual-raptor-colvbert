"""
ColModernVBERT vs ColVBERT æ¯”è¼ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆ
100æšã®Visual Documentã‚’ç”Ÿæˆã—ã€ä¸¡ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®æ€§èƒ½ã‚’æ¯”è¼ƒ
"""

import os
import sys
import time
import json
import torch
import numpy as np
from datetime import datetime
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from visual_raptor_colbert import VisualRAPTORColBERT, VisualDocument
from jina_vdr_benchmark import DisasterDocumentGenerator

print("=" * 80)
print("ColModernVBERT vs ColVBERT æ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
print("=" * 80)

# ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 1/10] ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™...")
output_dir = Path("data/encoder_comparison")
images_dir = output_dir / "images"
results_dir = output_dir / "results"

for dir_path in [output_dir, images_dir, results_dir]:
    dir_path.mkdir(parents=True, exist_ok=True)
    print(f"âœ… {dir_path} æº–å‚™å®Œäº†")

# ã‚¹ãƒ†ãƒƒãƒ—2: ç”»åƒç”Ÿæˆï¼ˆ100æšï¼‰
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 2/10] 100æšã®Visual Documentç”»åƒã‚’ç”Ÿæˆä¸­...")
doc_generator = DisasterDocumentGenerator()

# ç½å®³ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’100å€‹ç”Ÿæˆ
documents = doc_generator.create_synthetic_documents(num_documents=100)
print(f"âœ… {len(documents)}å€‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆå®Œäº†")

# å„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¯¾å¿œã™ã‚‹ç”»åƒã‚’ç”Ÿæˆ
visual_documents = []
for i, doc in enumerate(documents):
    # 640x480ã®ã‚«ãƒ©ãƒ¼ç”»åƒã‚’ç”Ÿæˆ
    img = Image.new('RGB', (640, 480), color=(255, 255, 255))
    draw = ImageDraw.Draw(img)
    
    # ã‚¿ã‚¤ãƒˆãƒ«ã¨å†…å®¹ã‚’æç”»
    try:
        font_title = ImageFont.truetype("arial.ttf", 24)
        font_content = ImageFont.truetype("arial.ttf", 14)
    except:
        font_title = ImageFont.load_default()
        font_content = ImageFont.load_default()
    
    # ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆä¸Šéƒ¨ï¼‰
    title = doc['title'][:50]  # 50æ–‡å­—ã¾ã§
    draw.text((10, 10), title, fill=(0, 0, 0), font=font_title)
    
    # æœ¬æ–‡ï¼ˆæŠ˜ã‚Šè¿”ã—å‡¦ç†ï¼‰
    content = doc['content']
    y_offset = 50
    max_width = 60  # 1è¡Œã‚ãŸã‚Šã®æ–‡å­—æ•°
    
    for line_start in range(0, min(len(content), 600), max_width):
        line = content[line_start:line_start + max_width]
        draw.text((10, y_offset), line, fill=(50, 50, 50), font=font_content)
        y_offset += 20
        if y_offset > 460:
            break
    
    # ç”»åƒã‚’ä¿å­˜
    img_path = images_dir / f"disaster_doc_{i:03d}.png"
    img.save(img_path)
    
    # VisualDocumentã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
    visual_doc = VisualDocument(
        image_path=str(img_path),
        text_content=doc['content'],
        metadata={
            'doc_id': doc['doc_id'],
            'title': doc['title'],
            'disaster_type': doc['disaster_type'],
            'location': doc['location'],
            'timestamp': doc['timestamp']
        }
    )
    visual_documents.append(visual_doc)
    
    if (i + 1) % 20 == 0:
        print(f"  ç”»åƒç”Ÿæˆé€²æ—: {i + 1}/100")

print(f"âœ… 100æšã®ç”»åƒã‚’ {images_dir} ã«ä¿å­˜å®Œäº†")

# ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¯ã‚¨ãƒªç”Ÿæˆï¼ˆ20å€‹ï¼‰
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 3/10] æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆä¸­...")
queries = doc_generator.generate_disaster_queries(num_queries=20)
print(f"âœ… {len(queries)}å€‹ã®ã‚¯ã‚¨ãƒªç”Ÿæˆå®Œäº†")

# ã‚¯ã‚¨ãƒªã‚’ä¿å­˜
queries_file = output_dir / "queries.json"
with open(queries_file, 'w', encoding='utf-8') as f:
    json.dump(queries, f, indent=2, ensure_ascii=False)
print(f"âœ… ã‚¯ã‚¨ãƒªã‚’ {queries_file} ã«ä¿å­˜")

# ã‚¹ãƒ†ãƒƒãƒ—4: ColVBERTåˆæœŸåŒ–ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 4/10] ColVBERT (BLIP) ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°...")

# Ollamaã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã¨LLMã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from langchain_ollama import OllamaEmbeddings, ChatOllama

embeddings_model = OllamaEmbeddings(
    model="mxbai-embed-large",
    base_url="http://localhost:11434"
)

llm = ChatOllama(
    model="granite-code:8b",
    base_url="http://localhost:11434",
    temperature=0.0,
    request_timeout=600.0
)

colbert_config = {
    'encoder_type': 'standard',
    'embedding_dim': 768,
    'use_cross_attention': False
}

colbert_system = VisualRAPTORColBERT(
    embeddings_model=embeddings_model,
    llm=llm,
    use_modern_vbert=False,
    colbert_config=colbert_config
)

print("ColVBERTåˆæœŸåŒ–å®Œäº† - ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é–‹å§‹...")
colbert_start_time = time.time()

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
colbert_embeddings = []
for i, visual_doc in enumerate(visual_documents):
    try:
        # ç”»åƒã‚’èª­ã¿è¾¼ã¿
        image = Image.open(visual_doc.image_path).convert('RGB')
        
        # ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        with torch.no_grad():
            text_emb = colbert_system.colbert_encoder.encode_text([visual_doc.text_content[:500]])  # 500æ–‡å­—ã¾ã§
            img_emb = colbert_system.colbert_encoder.encode_image([image])
            
            # å¹³å‡ã‚’å–ã‚‹
            combined_emb = (text_emb + img_emb) / 2.0
            colbert_embeddings.append(combined_emb.cpu().numpy())
        
        if (i + 1) % 20 == 0:
            print(f"  ColVBERT ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é€²æ—: {i + 1}/100")
    except Exception as e:
        print(f"  âš ï¸ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ {i} ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—: {e}")
        # ãƒ€ãƒŸãƒ¼åŸ‹ã‚è¾¼ã¿ã‚’è¿½åŠ 
        colbert_embeddings.append(np.random.randn(1, 768).astype(np.float32))

colbert_embeddings = np.vstack(colbert_embeddings)
colbert_encoding_time = time.time() - colbert_start_time

print(f"âœ… ColVBERT ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Œäº†")
print(f"  æ™‚é–“: {colbert_encoding_time:.2f}ç§’")
print(f"  åŸ‹ã‚è¾¼ã¿å½¢çŠ¶: {colbert_embeddings.shape}")

# ã‚¹ãƒ†ãƒƒãƒ—5: ColModernVBERTåˆæœŸåŒ–ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 5/10] ColModernVBERT (SigLIP) ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°...")
modern_config = {
    'encoder_type': 'modern',
    'embedding_dim': 768,
    'use_cross_attention': True
}

modern_system = VisualRAPTORColBERT(
    embeddings_model=embeddings_model,
    llm=llm,
    use_modern_vbert=True,
    colbert_config=modern_config
)

print("ColModernVBERTåˆæœŸåŒ–å®Œäº† - ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é–‹å§‹...")
modern_start_time = time.time()

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
modern_embeddings = []
for i, visual_doc in enumerate(visual_documents):
    try:
        # ç”»åƒã‚’èª­ã¿è¾¼ã¿
        image = Image.open(visual_doc.image_path).convert('RGB')
        
        # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        with torch.no_grad():
            multimodal_emb = modern_system.colbert_encoder.encode_multimodal(
                [visual_doc.text_content[:500]],  # 500æ–‡å­—ã¾ã§
                [image]
            )
            modern_embeddings.append(multimodal_emb.cpu().numpy())
        
        if (i + 1) % 20 == 0:
            print(f"  ColModernVBERT ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é€²æ—: {i + 1}/100")
    except Exception as e:
        print(f"  âš ï¸ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ {i} ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—: {e}")
        # ãƒ€ãƒŸãƒ¼åŸ‹ã‚è¾¼ã¿ã‚’è¿½åŠ 
        modern_embeddings.append(np.random.randn(1, 768).astype(np.float32))

modern_embeddings = np.vstack(modern_embeddings)
modern_encoding_time = time.time() - modern_start_time

print(f"âœ… ColModernVBERT ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Œäº†")
print(f"  æ™‚é–“: {modern_encoding_time:.2f}ç§’")
print(f"  åŸ‹ã‚è¾¼ã¿å½¢çŠ¶: {modern_embeddings.shape}")

# ã‚¹ãƒ†ãƒƒãƒ—6: ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆä¸¡æ–¹ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ï¼‰
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 6/10] ã‚¯ã‚¨ãƒªã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ä¸­...")

# ColVBERTã§ã‚¯ã‚¨ãƒªã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
colbert_query_embeddings = []
for query in queries:
    with torch.no_grad():
        query_emb = colbert_system.colbert_encoder.encode_text([query['query']])
        colbert_query_embeddings.append(query_emb.cpu().numpy())
colbert_query_embeddings = np.vstack(colbert_query_embeddings)

# ColModernVBERTã§ã‚¯ã‚¨ãƒªã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
modern_query_embeddings = []
for query in queries:
    with torch.no_grad():
        query_emb = modern_system.colbert_encoder.encode_text([query['query']])
        modern_query_embeddings.append(query_emb.cpu().numpy())
modern_query_embeddings = np.vstack(modern_query_embeddings)

print(f"âœ… ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Œäº†")
print(f"  ColVBERT ã‚¯ã‚¨ãƒªå½¢çŠ¶: {colbert_query_embeddings.shape}")
print(f"  ColModernVBERT ã‚¯ã‚¨ãƒªå½¢çŠ¶: {modern_query_embeddings.shape}")

# ã‚¹ãƒ†ãƒƒãƒ—7: æ¤œç´¢ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 7/10] æ¤œç´¢ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ä¸­...")

def compute_retrieval_metrics(query_embeddings, doc_embeddings, k=10):
    """æ¤œç´¢ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—"""
    num_queries = query_embeddings.shape[0]
    retrieval_times = []
    
    all_similarities = []
    
    for i in range(num_queries):
        start_time = time.time()
        
        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
        query_emb = query_embeddings[i]
        
        # æ­£è¦åŒ–
        query_norm = query_emb / (np.linalg.norm(query_emb) + 1e-8)
        doc_norms = doc_embeddings / (np.linalg.norm(doc_embeddings, axis=1, keepdims=True) + 1e-8)
        
        # é¡ä¼¼åº¦è¨ˆç®—
        similarities = np.dot(doc_norms, query_norm.T).flatten()
        
        # Top-kå–å¾—
        top_k_indices = np.argsort(similarities)[-k:][::-1]
        
        retrieval_time = time.time() - start_time
        retrieval_times.append(retrieval_time)
        all_similarities.append(similarities[top_k_indices])
    
    avg_retrieval_time = np.mean(retrieval_times)
    avg_similarity = np.mean([np.mean(sims) for sims in all_similarities])
    
    return {
        'avg_retrieval_time': avg_retrieval_time,
        'avg_similarity': avg_similarity,
        'total_time': np.sum(retrieval_times)
    }

# ColVBERTã®æ¤œç´¢è©•ä¾¡
colbert_metrics = compute_retrieval_metrics(colbert_query_embeddings, colbert_embeddings, k=10)
print(f"âœ… ColVBERT æ¤œç´¢è©•ä¾¡å®Œäº†")
print(f"  å¹³å‡æ¤œç´¢æ™‚é–“: {colbert_metrics['avg_retrieval_time']*1000:.2f}ms")
print(f"  å¹³å‡é¡ä¼¼åº¦: {colbert_metrics['avg_similarity']:.4f}")

# ColModernVBERTã®æ¤œç´¢è©•ä¾¡
modern_metrics = compute_retrieval_metrics(modern_query_embeddings, modern_embeddings, k=10)
print(f"âœ… ColModernVBERT æ¤œç´¢è©•ä¾¡å®Œäº†")
print(f"  å¹³å‡æ¤œç´¢æ™‚é–“: {modern_metrics['avg_retrieval_time']*1000:.2f}ms")
print(f"  å¹³å‡é¡ä¼¼åº¦: {modern_metrics['avg_similarity']:.4f}")

# ã‚¹ãƒ†ãƒƒãƒ—8: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®š
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 8/10] ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æ¸¬å®šä¸­...")

colbert_memory = colbert_embeddings.nbytes / (1024 * 1024)  # MB
modern_memory = modern_embeddings.nbytes / (1024 * 1024)  # MB

print(f"âœ… ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡")
print(f"  ColVBERT: {colbert_memory:.2f} MB")
print(f"  ColModernVBERT: {modern_memory:.2f} MB")

# ã‚¹ãƒ†ãƒƒãƒ—9: çµæœã®ä¿å­˜
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 9/10] æ¯”è¼ƒçµæœã‚’ä¿å­˜ä¸­...")

comparison_results = {
    'timestamp': datetime.now().isoformat(),
    'num_documents': len(visual_documents),
    'num_queries': len(queries),
    'colbert': {
        'encoder_type': 'standard (BLIP)',
        'encoding_time': float(colbert_encoding_time),
        'avg_retrieval_time_ms': float(colbert_metrics['avg_retrieval_time'] * 1000),
        'avg_similarity': float(colbert_metrics['avg_similarity']),
        'memory_mb': float(colbert_memory),
        'embedding_shape': list(colbert_embeddings.shape)
    },
    'colmodern_vbert': {
        'encoder_type': 'modern (SigLIP)',
        'encoding_time': float(modern_encoding_time),
        'avg_retrieval_time_ms': float(modern_metrics['avg_retrieval_time'] * 1000),
        'avg_similarity': float(modern_metrics['avg_similarity']),
        'memory_mb': float(modern_memory),
        'embedding_shape': list(modern_embeddings.shape)
    },
    'comparison': {
        'encoding_speedup': float(colbert_encoding_time / modern_encoding_time),
        'retrieval_speedup': float(colbert_metrics['avg_retrieval_time'] / modern_metrics['avg_retrieval_time']) if modern_metrics['avg_retrieval_time'] > 0 else float('inf'),
        'similarity_improvement': float(modern_metrics['avg_similarity'] - colbert_metrics['avg_similarity']),
        'memory_ratio': float(modern_memory / colbert_memory)
    }
}

results_file = results_dir / "comparison_results.json"
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(comparison_results, f, indent=2, ensure_ascii=False)

print(f"âœ… çµæœã‚’ {results_file} ã«ä¿å­˜")

# ã‚¹ãƒ†ãƒƒãƒ—10: çµæœã®å¯è¦–åŒ–ã¨ã‚µãƒãƒªãƒ¼
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 10/10] çµæœã®ã‚µãƒãƒªãƒ¼ã¨å¯è¦–åŒ–...")

print("\n" + "=" * 80)
print("ğŸ“Š ColModernVBERT vs ColVBERT æ¯”è¼ƒçµæœ")
print("=" * 80)

print("\nã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ€§èƒ½ã€‘")
print(f"ColVBERT (BLIP):         {colbert_encoding_time:.2f}ç§’")
print(f"ColModernVBERT (SigLIP): {modern_encoding_time:.2f}ç§’")
print(f"é«˜é€ŸåŒ–ç‡:                {comparison_results['comparison']['encoding_speedup']:.2f}x")

print("\nã€æ¤œç´¢æ€§èƒ½ã€‘")
print(f"ColVBERT å¹³å‡æ¤œç´¢æ™‚é–“:         {colbert_metrics['avg_retrieval_time']*1000:.2f}ms")
print(f"ColModernVBERT å¹³å‡æ¤œç´¢æ™‚é–“:   {modern_metrics['avg_retrieval_time']*1000:.2f}ms")
print(f"æ¤œç´¢é«˜é€ŸåŒ–ç‡:                  {comparison_results['comparison']['retrieval_speedup']:.2f}x")

print("\nã€é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã€‘")
print(f"ColVBERT å¹³å‡é¡ä¼¼åº¦:           {colbert_metrics['avg_similarity']:.4f}")
print(f"ColModernVBERT å¹³å‡é¡ä¼¼åº¦:     {modern_metrics['avg_similarity']:.4f}")
print(f"é¡ä¼¼åº¦æ”¹å–„:                    {comparison_results['comparison']['similarity_improvement']:.4f}")

print("\nã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã€‘")
print(f"ColVBERT:          {colbert_memory:.2f} MB")
print(f"ColModernVBERT:    {modern_memory:.2f} MB")
print(f"ãƒ¡ãƒ¢ãƒªæ¯”ç‡:        {comparison_results['comparison']['memory_ratio']:.2f}x")

# å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ä½œæˆ
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# 1. ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ™‚é–“æ¯”è¼ƒ
axes[0, 0].bar(['ColVBERT', 'ColModernVBERT'], 
               [colbert_encoding_time, modern_encoding_time],
               color=['#3498db', '#e74c3c'])
axes[0, 0].set_ylabel('Time (seconds)')
axes[0, 0].set_title('Encoding Time Comparison')
axes[0, 0].grid(axis='y', alpha=0.3)

# 2. æ¤œç´¢æ™‚é–“æ¯”è¼ƒ
axes[0, 1].bar(['ColVBERT', 'ColModernVBERT'], 
               [colbert_metrics['avg_retrieval_time']*1000, 
                modern_metrics['avg_retrieval_time']*1000],
               color=['#3498db', '#e74c3c'])
axes[0, 1].set_ylabel('Time (ms)')
axes[0, 1].set_title('Average Retrieval Time Comparison')
axes[0, 1].grid(axis='y', alpha=0.3)

# 3. é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢æ¯”è¼ƒ
axes[1, 0].bar(['ColVBERT', 'ColModernVBERT'], 
               [colbert_metrics['avg_similarity'], 
                modern_metrics['avg_similarity']],
               color=['#3498db', '#e74c3c'])
axes[1, 0].set_ylabel('Similarity Score')
axes[1, 0].set_title('Average Similarity Score Comparison')
axes[1, 0].grid(axis='y', alpha=0.3)

# 4. ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¯”è¼ƒ
axes[1, 1].bar(['ColVBERT', 'ColModernVBERT'], 
               [colbert_memory, modern_memory],
               color=['#3498db', '#e74c3c'])
axes[1, 1].set_ylabel('Memory (MB)')
axes[1, 1].set_title('Memory Usage Comparison')
axes[1, 1].grid(axis='y', alpha=0.3)

plt.tight_layout()
plot_file = results_dir / "comparison_plot.png"
plt.savefig(plot_file, dpi=150, bbox_inches='tight')
print(f"\nâœ… ã‚°ãƒ©ãƒ•ã‚’ {plot_file} ã«ä¿å­˜")

print("\n" + "=" * 80)
print("âœ… æ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†!")
print(f"ğŸ“ çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")
print(f"ğŸ“Š ç”»åƒ: {images_dir} (100æš)")
print(f"ğŸ“ˆ çµæœ: {results_dir}")
print("=" * 80)
