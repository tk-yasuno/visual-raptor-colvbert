#!/usr/bin/env python3
"""
Simple Visual RAPTOR ColBERT Demo
ã‚·ãƒ³ãƒ—ãƒ«ãªVisual RAPTOR ColBERTã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- Ollamaçµ±åˆç¢ºèª
- åŸºæœ¬çš„ãªæ¤œç´¢æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
- ç½å®³æ–‡æ›¸æ¤œç´¢ãƒ‡ãƒ¢
"""

import sys
import time
import json
from pathlib import Path
from typing import Dict, Any, List, Tuple

import numpy as np
from PIL import Image, ImageDraw, ImageFont

# LangChain imports
try:
    from langchain_ollama import OllamaEmbeddings, ChatOllama
    from langchain.schema import Document
    print("âœ… LangChain Ollama imports successful")
except ImportError as e:
    print(f"âŒ LangChain import error: {e}")
    sys.exit(1)


class SimpleDisasterDocument:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªç½å®³æ–‡æ›¸ã‚¯ãƒ©ã‚¹"""
    def __init__(self, doc_id: str, title: str, content: str, category: str, image_path: str = None):
        self.doc_id = doc_id
        self.title = title
        self.content = content
        self.category = category
        self.image_path = image_path
        self.metadata = {
            'title': title,
            'category': category,
            'doc_id': doc_id
        }


class SimpleVisualRAPTOR:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªVisual RAPTORã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, embeddings_model, llm):
        self.embeddings = embeddings_model
        self.llm = llm
        self.documents = []
        self.document_embeddings = []
        
    def add_documents(self, documents: List[SimpleDisasterDocument]):
        """æ–‡æ›¸ã‚’è¿½åŠ """
        print(f"ğŸ“š Adding {len(documents)} documents to index...")
        
        self.documents = documents
        
        # å„æ–‡æ›¸ã®åŸ‹ã‚è¾¼ã¿ã‚’è¨ˆç®—
        texts = [f"{doc.title}\n{doc.content}" for doc in documents]
        
        start_time = time.time()
        embeddings = []
        
        for i, text in enumerate(texts):
            embedding = self.embeddings.embed_query(text)
            embeddings.append(embedding)
            
            if (i + 1) % 5 == 0:
                print(f"   Processed {i + 1}/{len(texts)} documents")
        
        self.document_embeddings = np.array(embeddings)
        embed_time = time.time() - start_time
        
        print(f"âœ… Documents indexed in {embed_time:.2f}s")
        print(f"   Embedding dimension: {self.document_embeddings.shape[1]}")
        
    def search(self, query: str, top_k: int = 5) -> List[Tuple[SimpleDisasterDocument, float]]:
        """ã‚¯ã‚¨ãƒªã§æ¤œç´¢"""
        if not self.documents:
            return []
        
        # ã‚¯ã‚¨ãƒªã®åŸ‹ã‚è¾¼ã¿
        query_embedding = np.array(self.embeddings.embed_query(query))
        
        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
        similarities = np.dot(self.document_embeddings, query_embedding) / (
            np.linalg.norm(self.document_embeddings, axis=1) * np.linalg.norm(query_embedding)
        )
        
        # ãƒˆãƒƒãƒ—Kå–å¾—
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            doc = self.documents[idx]
            score = similarities[idx]
            results.append((doc, score))
        
        return results
    
    def generate_summary(self, query: str, top_documents: List[SimpleDisasterDocument]) -> str:
        """æ¤œç´¢çµæœã‚’è¦ç´„"""
        if not top_documents:
            return "é–¢é€£ã™ã‚‹æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        # æ–‡æ›¸å†…å®¹ã‚’çµåˆ
        context = "\n\n".join([
            f"ã€{doc.title}ã€‘\n{doc.content}"
            for doc in top_documents[:3]  # ä¸Šä½3æ–‡æ›¸
        ])
        
        # LLMã§è¦ç´„ç”Ÿæˆ
        prompt = f"""
ä»¥ä¸‹ã®ç½å®³é–¢é€£æ–‡æ›¸ã‚’å‚è€ƒã«ã€è³ªå•ã€Œ{query}ã€ã«å¯¾ã™ã‚‹å›ç­”ã‚’æ—¥æœ¬èªã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

é–¢é€£æ–‡æ›¸:
{context}

å›ç­”:"""
        
        try:
            response = self.llm.invoke(prompt)
            return response.content.strip()
        except Exception as e:
            return f"è¦ç´„ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"


class SimpleDemo:
    """ã‚·ãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¢ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.data_dir = Path("data/simple_demo")
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        self.embeddings = None
        self.llm = None
        self.raptor = None
        
    def initialize_ollama(self) -> bool:
        """Ollamaãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–"""
        print("ğŸ”§ Initializing Ollama models...")
        
        try:
            # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«
            print("   Loading embedding model (mxbai-embed-large)...")
            self.embeddings = OllamaEmbeddings(
                model="mxbai-embed-large",
                base_url="http://localhost:11434"
            )
            
            # ãƒ†ã‚¹ãƒˆ
            test_embed = self.embeddings.embed_query("test")
            print(f"   Embedding model loaded (dim: {len(test_embed)})")
            
            # LLMãƒ¢ãƒ‡ãƒ«
            print("   Loading LLM model (granite-code:8b)...")
            self.llm = ChatOllama(
                model="granite-code:8b",
                temperature=0.1,
                base_url="http://localhost:11434",
                timeout=120
            )
            
            # ãƒ†ã‚¹ãƒˆ
            test_response = self.llm.invoke("Hello")
            print(f"   LLM model loaded (response: {test_response.content[:30]}...)")
            
            # Visual RAPTORåˆæœŸåŒ–
            self.raptor = SimpleVisualRAPTOR(self.embeddings, self.llm)
            
            print("âœ… Ollama models initialized successfully")
            return True
            
        except Exception as e:
            print(f"âŒ Failed to initialize Ollama: {e}")
            print("Please ensure:")
            print("1. Ollama is running (ollama serve)")
            print("2. Models are downloaded:")
            print("   - ollama pull mxbai-embed-large")
            print("   - ollama pull granite-code:8b")
            return False
    
    def create_sample_disaster_documents(self) -> List[SimpleDisasterDocument]:
        """ã‚µãƒ³ãƒ—ãƒ«ç½å®³æ–‡æ›¸ã‚’ä½œæˆ"""
        print("ğŸ“„ Creating sample disaster documents...")
        
        sample_docs = [
            SimpleDisasterDocument(
                doc_id="doc_001",
                title="åœ°éœ‡ç™ºç”Ÿæ™‚ã®é¿é›£æ‰‹é †",
                content="""
1. ã¾ãšèº«ã®å®‰å…¨ã‚’ç¢ºä¿ã—ã¦ãã ã•ã„
2. æºã‚ŒãŒåã¾ã£ãŸã‚‰ç«ã®å§‹æœ«ã‚’ã—ã¦ãã ã•ã„
3. é¿é›£çµŒè·¯ã‚’ç¢ºèªã—ã€è½ä¸‹ç‰©ã«æ³¨æ„ã—ã¦ãã ã•ã„
4. æŒ‡å®šé¿é›£æ‰€ã«å‘ã‹ã£ã¦ãã ã•ã„
5. å®¶æ—ã®å®‰å¦ç¢ºèªã‚’è¡Œã£ã¦ãã ã•ã„
""",
                category="evacuation_procedure"
            ),
            SimpleDisasterDocument(
                doc_id="doc_002", 
                title="ç·Šæ€¥æ™‚é€£çµ¡å…ˆä¸€è¦§",
                content="""
ã€ç·Šæ€¥æ™‚é€£çµ¡å…ˆã€‘
â€¢ æ¶ˆé˜²ç½²: 119
â€¢ è­¦å¯Ÿç½²: 110  
â€¢ å¸‚å½¹æ‰€ç½å®³å¯¾ç­–æœ¬éƒ¨: 045-123-4567
â€¢ é¿é›£æ‰€ï¼ˆå°å­¦æ ¡ï¼‰: 045-123-4568
â€¢ åŒ»ç™‚æ©Ÿé–¢ï¼ˆç·åˆç—…é™¢ï¼‰: 045-123-4569
â€¢ ã‚¬ã‚¹ä¼šç¤¾ç·Šæ€¥é€£çµ¡å…ˆ: 045-123-4570
""",
                category="emergency_contact"
            ),
            SimpleDisasterDocument(
                doc_id="doc_003",
                title="é¿é›£æ‰€ã§ã®ç”Ÿæ´»ã‚¬ã‚¤ãƒ‰",
                content="""
ã€é¿é›£æ‰€ã§ã®éã”ã—æ–¹ã€‘
â€¢ å—ä»˜ã§æ°åãƒ»é€£çµ¡å…ˆã‚’è¨˜å…¥ã—ã¦ãã ã•ã„
â€¢ æŒ‡å®šã•ã‚ŒãŸå ´æ‰€ã§ç”Ÿæ´»ã—ã¦ãã ã•ã„
â€¢ é£Ÿäº‹ã¯æ±ºã‚ã‚‰ã‚ŒãŸæ™‚é–“ã«é…å¸ƒã•ã‚Œã¾ã™
â€¢ è¡›ç”Ÿç®¡ç†ã«æ°—ã‚’ã¤ã‘ã¦ãã ã•ã„
â€¢ ãƒšãƒƒãƒˆã¯å°‚ç”¨ã‚¨ãƒªã‚¢ã§ãŠä¸–è©±ãã ã•ã„
â€¢ å¤œé–“ã¯é™ç²›ã«ãŠéã”ã—ãã ã•ã„
""",
                category="shelter_guide"
            ),
            SimpleDisasterDocument(
                doc_id="doc_004",
                title="å‚™è“„å“ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ",
                content="""
ã€å¿…è¦ãªå‚™è“„å“ã€‘
é£Ÿæ–™å“:
â€¢ éå¸¸é£Ÿï¼ˆ3æ—¥åˆ†ï¼‰
â€¢ é£²æ–™æ°´ï¼ˆ1äºº1æ—¥3ãƒªãƒƒãƒˆãƒ«Ã—3æ—¥åˆ†ï¼‰
â€¢ ç¼¶è©°ãƒ»ãƒ¬ãƒˆãƒ«ãƒˆé£Ÿå“

ç”Ÿæ´»ç”¨å“:
â€¢ æ‡ä¸­é›»ç¯ãƒ»é›»æ± 
â€¢ ãƒ©ã‚¸ã‚ª
â€¢ å¿œæ€¥åŒ»è–¬å“
â€¢ æ¯›å¸ƒãƒ»ã‚¿ã‚ªãƒ«
â€¢ ç€æ›¿ãˆãƒ»ä¸‹ç€
""",
                category="emergency_supplies"
            ),
            SimpleDisasterDocument(
                doc_id="doc_005",
                title="æ´¥æ³¢è­¦å ±ç™ºä»¤æ™‚ã®å¯¾å¿œ",
                content="""
ã€æ´¥æ³¢è­¦å ±æ™‚ã®è¡Œå‹•ã€‘
1. ç›´ã¡ã«é«˜å°ã‚„é ‘ä¸ˆãªå»ºç‰©ã®3éšä»¥ä¸Šã«é¿é›£
2. è‡ªå‹•è»Šã§ã®é¿é›£ã¯æ¸‹æ»ã®åŸå› ã¨ãªã‚‹ãŸã‚å¾’æ­©ã§
3. æµ·å²¸ãƒ»æ²³å·ã«ã¯çµ¶å¯¾ã«è¿‘ã¥ã‹ãªã„
4. è­¦å ±è§£é™¤ã¾ã§çµ¶å¯¾ã«ä½åœ°ã«æˆ»ã‚‰ãªã„
5. æ­£ç¢ºãªæƒ…å ±åé›†ã«åŠªã‚ã‚‹ï¼ˆãƒ©ã‚¸ã‚ªãƒ»é˜²ç½ç„¡ç·šï¼‰
""",
                category="tsunami_response"
            ),
            SimpleDisasterDocument(
                doc_id="doc_006",
                title="å¿œæ€¥æ‰‹å½“ã®åŸºæœ¬",
                content="""
ã€åŸºæœ¬çš„ãªå¿œæ€¥æ‰‹å½“ã€‘
æ­¢è¡€:
â€¢ æ¸…æ½”ãªã‚¬ãƒ¼ã‚¼ã§å‚·å£ã‚’ç›´æ¥åœ§è¿«
â€¢ å‡ºè¡€ãŒå¤šã„å ´åˆã¯å¿ƒè‡“ã‚ˆã‚Šé«˜ã„ä½ç½®ã«

éª¨æŠ˜ã®ç–‘ã„:
â€¢ æ‚£éƒ¨ã‚’å›ºå®šã—ã€å‹•ã‹ã•ãªã„
â€¢ å‰¯æœ¨ã§æ‚£éƒ¨ã‚’æ”¯ãˆã‚‹

ã‚„ã‘ã©:
â€¢ æµæ°´ã§ååˆ†ã«å†·ã‚„ã™
â€¢ æ°´ã¶ãã‚Œã¯ç ´ã‚‰ãªã„
""",
                category="first_aid"
            ),
            SimpleDisasterDocument(
                doc_id="doc_007",
                title="åœé›»æ™‚ã®å¯¾å‡¦æ³•",
                content="""
ã€åœé›»æ™‚ã®å®‰å…¨å¯¾ç­–ã€‘
ç…§æ˜:
â€¢ æ‡ä¸­é›»ç¯ãƒ»ãƒ©ãƒ³ã‚¿ãƒ³ã‚’ä½¿ç”¨
â€¢ ã‚ã†ããã¯ç«ç½ã®å±é™ºãŒã‚ã‚‹ãŸã‚é¿ã‘ã‚‹

å†·è”µåº«:
â€¢ æ‰‰ã®é–‹é–‰ã‚’æœ€å°é™ã«
â€¢ ä¿å†·å‰¤ã‚’æ´»ç”¨

é€šä¿¡:
â€¢ æºå¸¯é›»è©±ã®ç¯€é›»ãƒ¢ãƒ¼ãƒ‰ä½¿ç”¨
â€¢ ä¹¾é›»æ± å¼ãƒ©ã‚¸ã‚ªã§æƒ…å ±åé›†
""",
                category="power_outage"
            ),
            SimpleDisasterDocument(
                doc_id="doc_008",
                title="é«˜é½¢è€…ãƒ»éšœå®³è€…æ”¯æ´ã‚¬ã‚¤ãƒ‰",
                content="""
ã€è¦é…æ…®è€…ã¸ã®æ”¯æ´ã€‘
é«˜é½¢è€…:
â€¢ ç§»å‹•ã®éš›ã¯è»¢å€’ã«æ³¨æ„
â€¢ è–¬ã®ç®¡ç†ãƒ»æœç”¨ç¢ºèª
â€¢ ä½“èª¿å¤‰åŒ–ã«æ³¨æ„

éšœå®³è€…:
â€¢ è¦–è¦šéšœå®³ï¼šæ‰‹å¼•ãã«ã‚ˆã‚‹èª˜å°
â€¢ è´è¦šéšœå®³ï¼šç­†è«‡ãƒ»æ‰‹è©±ã§ã®æƒ…å ±ä¼é”
â€¢ è»Šæ¤…å­åˆ©ç”¨è€…ï¼šæ®µå·®ã®ãªã„é¿é›£çµŒè·¯ç¢ºä¿
""",
                category="special_needs"
            )
        ]
        
        print(f"âœ… Created {len(sample_docs)} disaster documents")
        return sample_docs
    
    def create_sample_images(self, documents: List[SimpleDisasterDocument]):
        """ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ä½œæˆ"""
        print("ğŸ–¼ï¸ Creating sample document images...")
        
        images_dir = self.data_dir / "images"
        images_dir.mkdir(exist_ok=True)
        
        for doc in documents:
            # ç°¡å˜ãªæ–‡æ›¸ç”»åƒã‚’ä½œæˆ
            img = Image.new('RGB', (800, 600), 'white')
            draw = ImageDraw.Draw(img)
            
            # ã‚¿ã‚¤ãƒˆãƒ«
            draw.text((50, 50), doc.title, fill='black')
            
            # å†…å®¹ï¼ˆæœ€åˆã®æ•°è¡Œï¼‰
            content_lines = doc.content.strip().split('\n')[:10]
            for i, line in enumerate(content_lines):
                if line.strip():
                    draw.text((50, 100 + i*25), line[:60], fill='blue')
            
            # ã‚«ãƒ†ã‚´ãƒªãƒ©ãƒ™ãƒ«
            draw.text((600, 550), f"åˆ†é¡: {doc.category}", fill='red')
            
            # ä¿å­˜
            img_path = images_dir / f"{doc.doc_id}.png"
            img.save(img_path)
            doc.image_path = str(img_path)
        
        print(f"âœ… Created images for {len(documents)} documents")
    
    def run_search_demo(self, documents: List[SimpleDisasterDocument]) -> Dict[str, Any]:
        """æ¤œç´¢ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ"""
        print("ğŸ” Running search demonstration...")
        
        # æ–‡æ›¸ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¿½åŠ 
        self.raptor.add_documents(documents)
        
        # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
        test_queries = [
            "åœ°éœ‡ãŒèµ·ããŸã¨ãã¯ã©ã†ã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿ",
            "ç·Šæ€¥æ™‚ã®é€£çµ¡å…ˆã‚’æ•™ãˆã¦",
            "é¿é›£æ‰€ã§ã®ç”Ÿæ´»ã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã„",
            "æ´¥æ³¢è­¦å ±ãŒå‡ºãŸã¨ãã®å¯¾å¿œã¯ï¼Ÿ",
            "å¿œæ€¥æ‰‹å½“ã®æ–¹æ³•ã‚’æ•™ãˆã¦",
            "åœé›»ã—ãŸã¨ãã®å¯¾å‡¦æ³•ã¯ï¼Ÿ"
        ]
        
        search_results = {}
        
        for i, query in enumerate(test_queries):
            print(f"\nğŸ“‹ Query {i+1}: {query}")
            
            start_time = time.time()
            
            # æ¤œç´¢å®Ÿè¡Œ
            results = self.raptor.search(query, top_k=3)
            search_time = time.time() - start_time
            
            print(f"   Search time: {search_time:.3f}s")
            print("   Top results:")
            
            result_info = []
            for j, (doc, score) in enumerate(results):
                print(f"     {j+1}. {doc.title} (score: {score:.4f})")
                result_info.append({
                    'doc_id': doc.doc_id,
                    'title': doc.title,
                    'category': doc.category,
                    'score': float(score),
                    'content_preview': doc.content[:100] + "..."
                })
            
            # LLMã§è¦ç´„ç”Ÿæˆ
            print("   Generating summary...")
            top_docs = [doc for doc, _ in results]
            summary = self.raptor.generate_summary(query, top_docs)
            print(f"   Summary: {summary[:100]}...")
            
            search_results[f"query_{i+1}"] = {
                'query': query,
                'search_time': search_time,
                'results': result_info,
                'summary': summary
            }
        
        return search_results
    
    def save_results(self, results: Dict[str, Any]):
        """çµæœã‚’ä¿å­˜"""
        output_file = self.data_dir / "search_results.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ Results saved to {output_file}")
    
    def run_complete_demo(self) -> bool:
        """å®Œå…¨ãªãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ"""
        print("="*80)
        print("ğŸš€ Simple Visual RAPTOR Demo with Ollama")
        print("ç½å®³æ–‡æ›¸æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  ã‚·ãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¢")
        print("="*80)
        
        try:
            # 1. OllamaåˆæœŸåŒ–
            if not self.initialize_ollama():
                return False
            
            # 2. ã‚µãƒ³ãƒ—ãƒ«æ–‡æ›¸ä½œæˆ
            documents = self.create_sample_disaster_documents()
            
            # 3. ã‚µãƒ³ãƒ—ãƒ«ç”»åƒä½œæˆ
            self.create_sample_images(documents)
            
            # 4. æ¤œç´¢ãƒ‡ãƒ¢å®Ÿè¡Œ
            search_results = self.run_search_demo(documents)
            
            # 5. çµæœä¿å­˜
            self.save_results(search_results)
            
            # 6. ã‚µãƒãƒªãƒ¼è¡¨ç¤º
            print("\n" + "="*80)
            print("ğŸ“Š Demo Summary")
            print("="*80)
            print(f"Documents processed: {len(documents)}")
            print(f"Queries executed: {len(search_results)}")
            
            avg_search_time = np.mean([
                result['search_time'] for result in search_results.values()
            ])
            print(f"Average search time: {avg_search_time:.3f}s")
            
            print("\nğŸ‰ Simple demo completed successfully!")
            print(f"Results saved in: {self.data_dir}")
            print("="*80)
            
            return True
            
        except Exception as e:
            print(f"\nâŒ Demo failed: {e}")
            import traceback
            traceback.print_exc()
            return False


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    demo = SimpleDemo()
    success = demo.run_complete_demo()
    
    if success:
        print("\nâœ… Ollama integration successful!")
        print("Your Visual RAPTOR ColBERT system is working with:")
        print("  - Ollama mxbai-embed-large (embeddings)")
        print("  - Ollama granite-code:8b (LLM)")
        print("  - Disaster document search & summarization")
        print("\nNext: Try the full integrated system!")
    else:
        print("\nâŒ Demo failed. Please check Ollama setup.")
        sys.exit(1)


if __name__ == "__main__":
    main()