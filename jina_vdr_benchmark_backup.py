"""
JinaVDR (Visual Document Retrieval) ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµ±åˆ

éœ‡ç½é–¢é€£æ–‡æ›¸ã®æ¤œç´¢æ€§èƒ½è©•ä¾¡ç”¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
- æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¯¾å¿œ
- è¤‡é›‘ãªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ–‡æ›¸ï¼ˆã‚°ãƒ©ãƒ•ã€è¡¨ã€ã‚¹ã‚­ãƒ£ãƒ³ã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆï¼‰
- OCRãƒ†ã‚­ã‚¹ãƒˆä»˜ãç”»åƒï¼š500ï½1000æšè¦æ¨¡
- éœ‡ç½é–¢é€£æ–‡æ›¸ï¼ˆé¿é›£æ‰€ãƒãƒƒãƒ—ã€å¾©æ—§è¨ˆç”»ã€è¡Œæ”¿é€šçŸ¥ãªã©ï¼‰

Reference: jina-ai/jina-vdr
"""

import os
import json
import random
import numpy as np
from typing import List, Dict, Tuple, Optional, Any
from pathlib import Path
import urllib.request
import zipfile
from dataclasses import dataclass
import pandas as pd
from PIL import Image
import torch
from transformers import AutoTokenizer, AutoModel
import time

from visual_raptor_colbert import VisualDocument, VisualDocumentProcessor


@dataclass
class VDRQuery:
    """VDRã‚¯ã‚¨ãƒª"""
    query_id: str
    text: str
    language: str = "ja"
    category: str = "disaster"
    difficulty: str = "medium"


@dataclass
class VDRDocument:
    """VDRæ–‡æ›¸"""
    doc_id: str
    image_path: str
    text_content: str
    category: str
    subcategory: str
    metadata: Dict


@dataclass
class VDRRelevanceJudgment:
    """é–¢é€£æ€§åˆ¤å®š"""
    query_id: str
    doc_id: str
    relevance: int  # 0: ç„¡é–¢é€£, 1: é–¢é€£, 2: é«˜é–¢é€£


class JinaVDRBenchmark:
    """
    JinaVDR ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç®¡ç†ã‚¯ãƒ©ã‚¹
    
    éœ‡ç½é–¢é€£æ–‡æ›¸ã®æ¤œç´¢æ€§èƒ½è©•ä¾¡
    """
    
    def __init__(
        self,
        data_dir: str = "data/jina_vdr",
        language: str = "ja",
        dataset_size: str = "small"  # small: 500, medium: 1000, large: 2000+
    ):
        self.data_dir = Path(data_dir)
        self.language = language
        self.dataset_size = dataset_size
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
        self.images_dir = self.data_dir / "images"
        self.queries_dir = self.data_dir / "queries"
        self.annotations_dir = self.data_dir / "annotations"
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
        self.queries: List[VDRQuery] = []
        self.documents: List[VDRDocument] = []
        self.relevance_judgments: List[VDRRelevanceJudgment] = []
        
        self._create_directories()
        print(f"ğŸ“Š JinaVDR Benchmark initialized")
        print(f"   Language: {language}")
        print(f"   Dataset size: {dataset_size}")
        print(f"   Data directory: {data_dir}")
    
    def _create_directories(self):
        """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.images_dir.mkdir(exist_ok=True)
        self.queries_dir.mkdir(exist_ok=True)
        self.annotations_dir.mkdir(exist_ok=True)
    
    def generate_disaster_queries(self, num_queries: int = 50) -> List[VDRQuery]:
        """ç½å®³é–¢é€£ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ"""
        disaster_query_templates = [
            # é¿é›£ãƒ»å®‰å…¨
            ("é¿é›£æ‰€ã®å ´æ‰€ã‚’æ•™ãˆã¦ãã ã•ã„", "evacuation", "easy"),
            ("ç·Šæ€¥é¿é›£çµŒè·¯ã¯ã©ã“ã§ã™ã‹", "evacuation", "easy"),
            ("å®‰å…¨ãªé¿é›£å ´æ‰€ã¯ã‚ã‚Šã¾ã™ã‹", "evacuation", "easy"),
            ("æ´¥æ³¢é¿é›£ãƒ“ãƒ«ã®ä½ç½®", "evacuation", "medium"),
            ("é¿é›£æ‰€ã®åå®¹äººæ•°", "evacuation", "medium"),
            
            # å¾©æ—§ãƒ»å¾©èˆˆ
            ("å¾©æ—§å·¥äº‹ã®é€²æ—çŠ¶æ³", "recovery", "medium"),
            ("ã‚¤ãƒ³ãƒ•ãƒ©å¾©æ—§è¨ˆç”»", "recovery", "hard"),
            ("ä»®è¨­ä½å®…ã®é…ç½®å›³", "recovery", "medium"),
            ("å¾©èˆˆã¾ã¡ã¥ãã‚Šè¨ˆç”»", "recovery", "hard"),
            ("é“è·¯å¾©æ—§ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«", "recovery", "medium"),
            
            # è¡Œæ”¿ãƒ»æƒ…å ±
            ("ç½å®³å¯¾ç­–æœ¬éƒ¨ã‹ã‚‰ã®é€šçŸ¥", "administration", "easy"),
            ("é¿é›£æŒ‡ç¤ºã®è©³ç´°", "administration", "easy"),
            ("æ”¯æ´ç‰©è³‡ã®é…å¸ƒå ´æ‰€", "administration", "medium"),
            ("è¢«å®³çŠ¶æ³ã®å ±å‘Šæ›¸", "administration", "medium"),
            ("å¾©èˆˆäºˆç®—ã®å†…è¨³", "administration", "hard"),
            
            # é˜²ç½æ•™è‚²
            ("é˜²ç½è¨“ç·´ã®æ‰‹é †", "education", "easy"),
            ("ç½å®³æ™‚ã®è¡Œå‹•æŒ‡é‡", "education", "easy"),
            ("æ´¥æ³¢ã®å±é™ºæ€§ã«ã¤ã„ã¦", "education", "medium"),
            ("åœ°éœ‡ç™ºç”Ÿæ™‚ã®å¯¾å¿œ", "education", "medium"),
            ("é˜²ç½ãƒãƒƒãƒ—ã®è¦‹æ–¹", "education", "medium"),
            
            # è¢«å®³ãƒ»çµ±è¨ˆ
            ("è¢«å®³ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿", "statistics", "medium"),
            ("äººçš„è¢«å®³ã®çŠ¶æ³", "statistics", "hard"),
            ("å»ºç‰©è¢«å®³ã®åˆ†æ", "statistics", "hard"),
            ("çµŒæ¸ˆçš„æå¤±ã®è©•ä¾¡", "statistics", "hard"),
            ("å¾©èˆˆé€²æ—ã®æŒ‡æ¨™", "statistics", "hard"),
        ]
        
        queries = []
        for i in range(num_queries):
            template = random.choice(disaster_query_templates)
            query = VDRQuery(
                query_id=f"query_{i:03d}",
                text=template[0],
                language=self.language,
                category=template[1],
                difficulty=template[2]
            )
            queries.append(query)
        
        self.queries = queries
        return queries
    
    def create_synthetic_documents(
        self,
        num_documents: int = 500,
        base_text_dir: str = None
    ) -> List[VDRDocument]:
        """åˆæˆæ–‡æ›¸ã‚’ä½œæˆ"""
        if base_text_dir is None:
            base_text_dir = str(Path(__file__).parent / "0_base_tsunami-lesson-rag")
        
        # ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        base_text = self._load_base_text_data(base_text_dir)
        
        # æ–‡æ›¸ã‚«ãƒ†ã‚´ãƒª
        doc_categories = {
            "evacuation_map": "é¿é›£ãƒãƒƒãƒ—",
            "recovery_plan": "å¾©æ—§è¨ˆç”»æ›¸",
            "admin_notice": "è¡Œæ”¿é€šçŸ¥",
            "damage_report": "è¢«å®³å ±å‘Šæ›¸",
            "education_material": "é˜²ç½æ•™è‚²è³‡æ–™",
            "statistics": "çµ±è¨ˆãƒ‡ãƒ¼ã‚¿",
            "infrastructure": "ã‚¤ãƒ³ãƒ•ãƒ©æƒ…å ±",
            "support_info": "æ”¯æ´æƒ…å ±"
        }
        
        documents = []
        visual_processor = VisualDocumentProcessor()\n        \n        for i in range(num_documents):\n            # ã‚«ãƒ†ã‚´ãƒªã‚’ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ\n            category = random.choice(list(doc_categories.keys()))\n            subcategory = doc_categories[category]\n            \n            # åˆæˆç”»åƒã‚’ç”Ÿæˆï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯å®Ÿéš›ã®ç”»åƒã‚’ä½¿ç”¨ï¼‰\n            image_path = self._create_synthetic_image(\n                category, i, subcategory\n            )\n            \n            # ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ\n            text_content = self._generate_document_text(\n                base_text, category, subcategory\n            )\n            \n            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿\n            metadata = {\n                "created_date": "2024-01-01",\n                "source": "synthetic",\n                "format": "image_with_text",\n                "processing_method": "ocr_extracted"\n            }\n            \n            doc = VDRDocument(\n                doc_id=f"doc_{i:04d}",\n                image_path=str(image_path),\n                text_content=text_content,\n                category=category,\n                subcategory=subcategory,\n                metadata=metadata\n            )\n            documents.append(doc)\n        \n        self.documents = documents\n        print(f"âœ… Created {len(documents)} synthetic documents")\n        return documents\n    \n    def _load_base_text_data(self, base_dir: str) -> str:\n        """ãƒ™ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""\n        try:\n            with open(Path(base_dir) / "tohoku_earthquake_data.txt", 'r', encoding='utf-8') as f:\n                return f.read()\n        except FileNotFoundError:\n            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šåŸºæœ¬çš„ãªç½å®³é–¢é€£ãƒ†ã‚­ã‚¹ãƒˆ\n            return """\næ±æ—¥æœ¬å¤§éœ‡ç½ã«ãŠã‘ã‚‹æ•™è¨“ã¨å¯¾å¿œ\n\n1. é¿é›£è¡Œå‹•\næ´¥æ³¢è­¦å ±ç™ºè¡¨æ™‚ã«ã¯ã€ç›´ã¡ã«é«˜å°ã¸ã®é¿é›£ãŒé‡è¦ã§ã‚ã‚‹ã€‚\né‡œçŸ³å¸‚ã§ã¯ã€Œæ´¥æ³¢ã¦ã‚“ã§ã‚“ã“ã€ã®æ•™ãˆã«ã‚ˆã‚Šå¤šãã®å‘½ãŒæ•‘ã‚ã‚ŒãŸã€‚\n\n2. æƒ…å ±ä¼é”\né˜²ç½è¡Œæ”¿ç„¡ç·šã€æºå¸¯é›»è©±ã®ç·Šæ€¥é€Ÿå ±ãƒ¡ãƒ¼ãƒ«ç­‰ã®æ´»ç”¨\nåœé›»æ™‚ã®æƒ…å ±åé›†æ‰‹æ®µã®ç¢ºä¿ãŒèª²é¡Œ\n\n3. é¿é›£æ‰€é‹å–¶\né¿é›£æ‰€ã®é‹å–¶ã«ã¯åœ°åŸŸä½æ°‘ã®å”åŠ›ãŒä¸å¯æ¬ \nè¦é…æ…®è€…ã¸ã®æ”¯æ´ä½“åˆ¶ã®æ§‹ç¯‰\n\n4. å¾©æ—§ãƒ»å¾©èˆˆ\nã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãƒ‘ãƒ¼ãƒˆæ–¹å¼ã«ã‚ˆã‚‹æ”¯æ´\nå‰µé€ çš„å¾©èˆˆã®ç†å¿µã«åŸºã¥ãå–ã‚Šçµ„ã¿\n"""\n    \n    def _generate_document_text(self, base_text: str, category: str, subcategory: str) -> str:\n        """æ–‡æ›¸ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""\n        # ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ãŸãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ\n        category_texts = {\n            "evacuation_map": f"""\n{subcategory}\n\né¿é›£å ´æ‰€ï¼šâ—‹â—‹å°å­¦æ ¡ä½“è‚²é¤¨\nåå®¹äººæ•°ï¼š200å\næ‰€åœ¨åœ°ï¼šâ—‹â—‹å¸‚â—‹â—‹ç”º1-1-1\né€£çµ¡å…ˆï¼šXXX-XXX-XXXX\n\né¿é›£çµŒè·¯ï¼š\n- å›½é“â—‹å·ç·šã‚’åŒ—ä¸Š\n- â—‹â—‹æ©‹ã‚’æ¸¡ã‚‹\n- ä¿¡å·ã‚’å³æŠ˜\n\næ³¨æ„äº‹é …ï¼š\n- å¾’æ­©ã§ã®é¿é›£ã‚’æ¨å¥¨\n- ãƒšãƒƒãƒˆåŒä¼´å¯\n- é£Ÿæ–™ãƒ»æ°´ã¯3æ—¥åˆ†æŒå‚\n""",\n            "recovery_plan": f"""\n{subcategory}\n\nå¾©æ—§è¨ˆç”»æ¦‚è¦\nå¯¾è±¡åœ°åŸŸï¼šâ—‹â—‹åœ°åŒº\næœŸé–“ï¼š2024å¹´4æœˆï½2025å¹´3æœˆ\n\nä¸»è¦é …ç›®ï¼š\n1. é“è·¯å¾©æ—§ï¼ˆâ—‹â—‹é“è·¯ä»–ï¼‰\n2. ä¸Šä¸‹æ°´é“å¾©æ—§\n3. é›»åŠ›ã‚¤ãƒ³ãƒ•ãƒ©å¾©æ—§\n4. é€šä¿¡è¨­å‚™å¾©æ—§\n\näºˆç®—ï¼šç·é¡â—‹â—‹å„„å††\né€²æ—ï¼šç¾åœ¨30%å®Œäº†\n""",\n            "admin_notice": f"""\nè¡Œæ”¿ã‹ã‚‰ã®ãŠçŸ¥ã‚‰ã›\n\nä»¶åï¼š{subcategory}\nç™ºè¡Œæ—¥ï¼š2024å¹´1æœˆ15æ—¥\nç™ºè¡Œè€…ï¼šâ—‹â—‹å¸‚ç½å®³å¯¾ç­–æœ¬éƒ¨\n\nå¸‚æ°‘ã®çš†æ§˜ã¸\n\nâ—‹â—‹åœ°åŒºã«ãŠã‘ã‚‹å¾©æ—§ä½œæ¥­ã«ã¤ã„ã¦ä¸‹è¨˜ã®é€šã‚ŠãŠçŸ¥ã‚‰ã›ã„ãŸã—ã¾ã™ã€‚\n\nè©³ç´°ã¯å¸‚ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ã‚’ã”ç¢ºèªãã ã•ã„ã€‚\nå•ã„åˆã‚ã›å…ˆï¼šâ—‹â—‹å¸‚å½¹æ‰€ XXX-XXX-XXXX\n"""\n        }\n        \n        return category_texts.get(category, f"{subcategory}\\n\\né–¢é€£æƒ…å ±ï¼š\\n{base_text[:500]}...")\n    \n    def _create_synthetic_image(\n        self, \n        category: str, \n        index: int, \n        subcategory: str\n    ) -> Path:\n        """åˆæˆç”»åƒã‚’ä½œæˆ"""\n        # ç°¡å˜ãªåˆæˆç”»åƒã‚’ä½œæˆï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã‚ˆã‚Šè¤‡é›‘ãªç”»åƒç”ŸæˆãŒå¿…è¦ï¼‰\n        from PIL import Image, ImageDraw, ImageFont\n        \n        # ç”»åƒã‚µã‚¤ã‚ºã¨ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ\n        width, height = 800, 600\n        image = Image.new('RGB', (width, height), 'white')\n        draw = ImageDraw.Draw(image)\n        \n        # ãƒ•ã‚©ãƒ³ãƒˆï¼ˆã‚·ã‚¹ãƒ†ãƒ ã«ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰\n        try:\n            font = ImageFont.truetype("arial.ttf", 20)\n            title_font = ImageFont.truetype("arial.ttf", 30)\n        except:\n            font = ImageFont.load_default()\n            title_font = ImageFont.load_default()\n        \n        # ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ãŸç”»åƒç”Ÿæˆ\n        if category == "evacuation_map":\n            # é¿é›£ãƒãƒƒãƒ—é¢¨\n            draw.rectangle([50, 50, width-50, height-50], outline='black', width=2)\n            draw.text((60, 60), "é¿é›£ãƒãƒƒãƒ—", fill='black', font=title_font)\n            draw.text((60, 100), subcategory, fill='blue', font=font)\n            \n            # ç°¡å˜ãªåœ°å›³è¦ç´ \n            draw.rectangle([100, 150, 200, 200], fill='green', outline='black')\n            draw.text((105, 165), "é¿é›£æ‰€", fill='white', font=font)\n            \n            draw.line([(250, 175), (400, 175)], fill='gray', width=3)\n            draw.text((300, 180), "é¿é›£çµŒè·¯", fill='black', font=font)\n            \n        elif category == "recovery_plan":\n            # å¾©æ—§è¨ˆç”»æ›¸é¢¨\n            draw.rectangle([50, 50, width-50, height-50], outline='navy', width=3)\n            draw.text((60, 60), "å¾©æ—§è¨ˆç”»æ›¸", fill='navy', font=title_font)\n            draw.text((60, 100), subcategory, fill='black', font=font)\n            \n            # è¡¨é¢¨ã®è¦ç´ \n            for i in range(4):\n                y = 150 + i * 40\n                draw.rectangle([100, y, 600, y+30], outline='black')\n                draw.text((110, y+5), f"é …ç›® {i+1}", fill='black', font=font)\n        \n        elif category == "admin_notice":\n            # è¡Œæ”¿é€šçŸ¥é¢¨\n            draw.rectangle([50, 50, width-50, height-50], outline='red', width=2)\n            draw.text((60, 60), "è¡Œæ”¿é€šçŸ¥", fill='red', font=title_font)\n            draw.text((60, 100), subcategory, fill='black', font=font)\n            \n            # é‡è¦ãƒãƒ¼ã‚¯\n            draw.ellipse([width-150, 60, width-60, 120], fill='red')\n            draw.text((width-140, 80), "é‡è¦", fill='white', font=font)\n        \n        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜\n        image_path = self.images_dir / f"{category}_{index:04d}.png"\n        image.save(image_path)\n        \n        return image_path\n    \n    def generate_relevance_judgments(\n        self,\n        num_judgments_per_query: int = 10\n    ) -> List[VDRRelevanceJudgment]:\n        """é–¢é€£æ€§åˆ¤å®šã‚’ç”Ÿæˆ"""\n        judgments = []\n        \n        for query in self.queries:\n            # ã‚¯ã‚¨ãƒªã‚«ãƒ†ã‚´ãƒªã«åŸºã¥ã„ã¦é–¢é€£æ–‡æ›¸ã‚’é¸æŠ\n            relevant_docs = [doc for doc in self.documents \n                           if self._is_relevant(query.category, doc.category)]\n            \n            # é–¢é€£æ–‡æ›¸ã‹ã‚‰ä¸€éƒ¨ã‚’é¸æŠ\n            selected_docs = random.sample(\n                relevant_docs, \n                min(num_judgments_per_query, len(relevant_docs))\n            )\n            \n            for doc in selected_docs:\n                # é–¢é€£æ€§ã‚¹ã‚³ã‚¢ã‚’æ±ºå®š\n                relevance = self._calculate_relevance(query, doc)\n                \n                judgment = VDRRelevanceJudgment(\n                    query_id=query.query_id,\n                    doc_id=doc.doc_id,\n                    relevance=relevance\n                )\n                judgments.append(judgment)\n        \n        self.relevance_judgments = judgments\n        print(f"âœ… Generated {len(judgments)} relevance judgments")\n        return judgments\n    \n    def _is_relevant(self, query_category: str, doc_category: str) -> bool:\n        """ã‚¯ã‚¨ãƒªã¨æ–‡æ›¸ã®é–¢é€£æ€§ã‚’åˆ¤å®š"""\n        # ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ”ãƒ³ã‚°\n        category_mapping = {\n            "evacuation": ["evacuation_map", "admin_notice", "education_material"],\n            "recovery": ["recovery_plan", "infrastructure", "statistics"],\n            "administration": ["admin_notice", "damage_report", "support_info"],\n            "education": ["education_material", "evacuation_map"],\n            "statistics": ["statistics", "damage_report"]\n        }\n        \n        return doc_category in category_mapping.get(query_category, [])\n    \n    def _calculate_relevance(self, query: VDRQuery, doc: VDRDocument) -> int:\n        """é–¢é€£æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""\n        # ç°¡å˜ãªãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯\n        if query.category == doc.category:\n            return random.choice([1, 2])  # é–¢é€£ã¾ãŸã¯é«˜é–¢é€£\n        elif self._is_relevant(query.category, doc.category):\n            return 1  # é–¢é€£\n        else:\n            return 0  # ç„¡é–¢é€£\n    \n    def save_benchmark_data(self):\n        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""\n        # ã‚¯ã‚¨ãƒªä¿å­˜\n        queries_data = [\n            {\n                "query_id": q.query_id,\n                "text": q.text,\n                "language": q.language,\n                "category": q.category,\n                "difficulty": q.difficulty\n            }\n            for q in self.queries\n        ]\n        \n        with open(self.queries_dir / "queries.json", 'w', encoding='utf-8') as f:\n            json.dump(queries_data, f, ensure_ascii=False, indent=2)\n        \n        # æ–‡æ›¸ä¿å­˜\n        documents_data = [\n            {\n                "doc_id": d.doc_id,\n                "image_path": d.image_path,\n                "text_content": d.text_content,\n                "category": d.category,\n                "subcategory": d.subcategory,\n                "metadata": d.metadata\n            }\n            for d in self.documents\n        ]\n        \n        with open(self.annotations_dir / "documents.json", 'w', encoding='utf-8') as f:\n            json.dump(documents_data, f, ensure_ascii=False, indent=2)\n        \n        # é–¢é€£æ€§åˆ¤å®šä¿å­˜\n        judgments_data = [\n            {\n                "query_id": j.query_id,\n                "doc_id": j.doc_id,\n                "relevance": j.relevance\n            }\n            for j in self.relevance_judgments\n        ]\n        \n        with open(self.annotations_dir / "relevance_judgments.json", 'w', encoding='utf-8') as f:\n            json.dump(judgments_data, f, ensure_ascii=False, indent=2)\n        \n        print(f"âœ… Benchmark data saved to {self.data_dir}")\n    \n    def load_benchmark_data(self):\n        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""\n        # ã‚¯ã‚¨ãƒªèª­ã¿è¾¼ã¿\n        queries_file = self.queries_dir / "queries.json"\n        if queries_file.exists():\n            with open(queries_file, 'r', encoding='utf-8') as f:\n                queries_data = json.load(f)\n            \n            self.queries = [\n                VDRQuery(**q) for q in queries_data\n            ]\n        \n        # æ–‡æ›¸èª­ã¿è¾¼ã¿\n        documents_file = self.annotations_dir / "documents.json"\n        if documents_file.exists():\n            with open(documents_file, 'r', encoding='utf-8') as f:\n                documents_data = json.load(f)\n            \n            self.documents = [\n                VDRDocument(**d) for d in documents_data\n            ]\n        \n        # é–¢é€£æ€§åˆ¤å®šèª­ã¿è¾¼ã¿\n        judgments_file = self.annotations_dir / "relevance_judgments.json"\n        if judgments_file.exists():\n            with open(judgments_file, 'r', encoding='utf-8') as f:\n                judgments_data = json.load(f)\n            \n            self.relevance_judgments = [\n                VDRRelevanceJudgment(**j) for j in judgments_data\n            ]\n        \n        print(f"âœ… Benchmark data loaded from {self.data_dir}")\n        print(f"   Queries: {len(self.queries)}")\n        print(f"   Documents: {len(self.documents)}")\n        print(f"   Judgments: {len(self.relevance_judgments)}")\n    \n    def get_benchmark_statistics(self) -> Dict[str, Any]:\n        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµ±è¨ˆã‚’å–å¾—"""\n        stats = {\n            "num_queries": len(self.queries),\n            "num_documents": len(self.documents),\n            "num_judgments": len(self.relevance_judgments),\n            "query_categories": {},\n            "document_categories": {},\n            "relevance_distribution": {0: 0, 1: 0, 2: 0}\n        }\n        \n        # ã‚¯ã‚¨ãƒªã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ\n        for query in self.queries:\n            stats["query_categories"][query.category] = \\\n                stats["query_categories"].get(query.category, 0) + 1\n        \n        # æ–‡æ›¸ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ\n        for doc in self.documents:\n            stats["document_categories"][doc.category] = \\\n                stats["document_categories"].get(doc.category, 0) + 1\n        \n        # é–¢é€£æ€§åˆ†å¸ƒ\n        for judgment in self.relevance_judgments:\n            stats["relevance_distribution"][judgment.relevance] += 1\n        \n        return stats\n\n\ndef create_jina_vdr_benchmark(\n    data_dir: str = "data/jina_vdr",\n    num_queries: int = 50,\n    num_documents: int = 500,\n    dataset_size: str = "small"\n) -> JinaVDRBenchmark:\n    """JinaVDRãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä½œæˆ"""\n    print("="*80)\n    print("Creating JinaVDR Benchmark for Disaster Document Retrieval")\n    print("="*80)\n    \n    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯åˆæœŸåŒ–\n    benchmark = JinaVDRBenchmark(\n        data_dir=data_dir,\n        language="ja",\n        dataset_size=dataset_size\n    )\n    \n    # ã‚¯ã‚¨ãƒªç”Ÿæˆ\n    print(f"\\nğŸ” Generating {num_queries} queries...")\n    benchmark.generate_disaster_queries(num_queries)\n    \n    # æ–‡æ›¸ç”Ÿæˆ\n    print(f"\\nğŸ“„ Creating {num_documents} synthetic documents...")\n    benchmark.create_synthetic_documents(num_documents)\n    \n    # é–¢é€£æ€§åˆ¤å®šç”Ÿæˆ\n    print(f"\\nğŸ“Š Generating relevance judgments...")\n    benchmark.generate_relevance_judgments()\n    \n    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜\n    print(f"\\nğŸ’¾ Saving benchmark data...")\n    benchmark.save_benchmark_data()\n    \n    # çµ±è¨ˆè¡¨ç¤º\n    stats = benchmark.get_benchmark_statistics()\n    print(f"\\nğŸ“ˆ Benchmark Statistics:")\n    print(f"   Queries: {stats['num_queries']}")\n    print(f"   Documents: {stats['num_documents']}")\n    print(f"   Judgments: {stats['num_judgments']}")\n    print(f"   Query categories: {list(stats['query_categories'].keys())}")\n    print(f"   Document categories: {list(stats['document_categories'].keys())}")\n    \n    print(f"\\nâœ… JinaVDR benchmark created successfully!")\n    print(f"   Data directory: {data_dir}")\n    \n    return benchmark\n\n\ndef main():\n    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""\n    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä½œæˆ\n    benchmark = create_jina_vdr_benchmark(\n        data_dir="data/jina_vdr_disaster",\n        num_queries=50,\n        num_documents=500,\n        dataset_size="small"\n    )\n    \n    print("\\n" + "="*80)\n    print("JinaVDR Benchmark Setup Complete")\n    print("="*80)\n\n\nif __name__ == "__main__":\n    main()