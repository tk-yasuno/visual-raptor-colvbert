"""
å®Ÿéš›ã®PDFç½å®³æ–‡æ›¸ã‚’å‡¦ç†ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
PDFã‚’ç”»åƒã«å¤‰æ›ã—ã¦Visual RAPTOR ColBERTã§æ¤œç´¢å¯èƒ½ã«ã™ã‚‹
"""

import os
import sys
from pathlib import Path
from PIL import Image
import torch

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from visual_raptor_colbert import VisualRAPTORColBERT, VisualDocument
from langchain_ollama import OllamaEmbeddings, ChatOllama

print("=" * 80)
print("ğŸ“„ PDFç½å®³æ–‡æ›¸å‡¦ç† - Visual RAPTOR ColBERT")
print("=" * 80)

# PDFãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
pdf_dir = Path("data/disaster_visual_documents")
output_dir = Path("data/processed_pdfs")
images_dir = output_dir / "images"
images_dir.mkdir(parents=True, exist_ok=True)

# PDFãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
pdf_files = list(pdf_dir.glob("*.pdf"))
print(f"\nğŸ“ æ¤œå‡ºã•ã‚ŒãŸPDFãƒ•ã‚¡ã‚¤ãƒ«: {len(pdf_files)}å€‹")
for i, pdf_file in enumerate(pdf_files, 1):
    print(f"  {i}. {pdf_file.name}")

if not pdf_files:
    print("âŒ PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    sys.exit(1)

# PDF to Image å¤‰æ›
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 1/6] PDFã‚’ç”»åƒã«å¤‰æ›ä¸­...")

try:
    # PyMuPDFã‚’ä½¿ç”¨ï¼ˆpopplerä¸è¦ï¼‰
    import fitz  # PyMuPDF
    
    all_images = []
    doc_metadata = []
    
    for pdf_file in pdf_files:
        print(f"\n  ğŸ“„ å‡¦ç†ä¸­: {pdf_file.name}")
        
        try:
            # PDFã‚’é–‹ã
            pdf_document = fitz.open(str(pdf_file))
            num_pages = len(pdf_document)
            
            print(f"    âœ… {num_pages}ãƒšãƒ¼ã‚¸ã‚’æ¤œå‡º")
            
            # å„ãƒšãƒ¼ã‚¸ã‚’ç”»åƒã«å¤‰æ›
            for page_num in range(num_pages):
                page = pdf_document[page_num]
                
                # ãƒšãƒ¼ã‚¸ã‚’ç”»åƒã«å¤‰æ›ï¼ˆ150 DPIï¼‰
                mat = fitz.Matrix(150/72, 150/72)  # 150 DPI
                pix = page.get_pixmap(matrix=mat)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
                safe_name = pdf_file.stem.replace(' ', '_')
                img_path = images_dir / f"{safe_name}_page{page_num+1:03d}.png"
                
                # ç”»åƒä¿å­˜
                pix.save(str(img_path))
                
                # PIL Imageã¨ã—ã¦èª­ã¿è¾¼ã¿
                image = Image.open(img_path)
                all_images.append(image)
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                doc_metadata.append({
                    'pdf_name': pdf_file.name,
                    'page_number': page_num + 1,
                    'total_pages': num_pages,
                    'image_path': str(img_path)
                })
                
                if page_num < 3:
                    print(f"      - ãƒšãƒ¼ã‚¸ {page_num+1}: {img_path.name}")
            
            if num_pages > 3:
                print(f"      ... (æ®‹ã‚Š {num_pages - 3} ãƒšãƒ¼ã‚¸)")
            
            pdf_document.close()
                
        except Exception as e:
            print(f"    âš ï¸ ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    print(f"\nâœ… åˆè¨ˆ {len(all_images)} ãƒšãƒ¼ã‚¸ã®ç”»åƒã‚’ç”Ÿæˆ")
    
except ImportError:
    print("\nâš ï¸ PyMuPDFãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    print("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•:")
    print("  pip install PyMuPDF")
    sys.exit(1)

# Ollamaãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 2/6] Ollamaãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–...")
embeddings_model = OllamaEmbeddings(
    model="mxbai-embed-large",
    base_url="http://localhost:11434"
)

llm = ChatOllama(
    model="granite-code:8b",
    base_url="http://localhost:11434",
    temperature=0.0,
    request_timeout=600.0
)
print("âœ… OllamaåˆæœŸåŒ–å®Œäº†")

# ColModernVBERTåˆæœŸåŒ–
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 3/6] ColModernVBERT (SigLIP) åˆæœŸåŒ–...")
config = {
    'encoder_type': 'modern',
    'embedding_dim': 768,
    'use_cross_attention': True
}

visual_raptor = VisualRAPTORColBERT(
    embeddings_model=embeddings_model,
    llm=llm,
    use_modern_vbert=True,
    colbert_config=config
)
print("âœ… Visual RAPTOR ColBERTåˆæœŸåŒ–å®Œäº†")

# OCRå‡¦ç†ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 4/6] OCRãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰...")
try:
    import pytesseract
    from PIL import Image as PILImage
    
    print("  Tesseract OCRã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºä¸­...")
    
    for i, metadata in enumerate(doc_metadata):
        try:
            image = PILImage.open(metadata['image_path'])
            text = pytesseract.image_to_string(
                image,
                lang='jpn+eng',
                config='--psm 6'
            )
            metadata['ocr_text'] = text[:1000]  # æœ€åˆã®1000æ–‡å­—
            
            if (i + 1) % 5 == 0:
                print(f"    é€²æ—: {i + 1}/{len(doc_metadata)}")
        except Exception as e:
            metadata['ocr_text'] = ""
            print(f"    âš ï¸ ãƒšãƒ¼ã‚¸ {i+1} OCRã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"  âœ… {len(doc_metadata)}ãƒšãƒ¼ã‚¸ã®OCRå®Œäº†")
    
except ImportError:
    print("  âš ï¸ Tesseract OCRãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
    for metadata in doc_metadata:
        metadata['ocr_text'] = f"{metadata['pdf_name']} - ãƒšãƒ¼ã‚¸ {metadata['page_number']}"

# Visual Documentã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 5/6] Visual Documentã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°...")
import time
start_time = time.time()

encoded_docs = []
for i, metadata in enumerate(doc_metadata):
    try:
        image = Image.open(metadata['image_path']).convert('RGB')
        text = metadata['ocr_text']
        
        # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        with torch.no_grad():
            embedding = visual_raptor.colbert_encoder.encode_multimodal(
                [text],
                [image]
            )
        
        encoded_docs.append({
            'metadata': metadata,
            'embedding': embedding.detach().cpu()
        })
        
        if (i + 1) % 10 == 0:
            print(f"  é€²æ—: {i + 1}/{len(doc_metadata)}")
    
    except Exception as e:
        print(f"  âš ï¸ ãƒšãƒ¼ã‚¸ {i+1} ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        continue

encoding_time = time.time() - start_time
print(f"âœ… {len(encoded_docs)}ãƒšãƒ¼ã‚¸ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å®Œäº† ({encoding_time:.2f}ç§’)")
print(f"   å¹³å‡: {encoding_time/len(encoded_docs):.3f}ç§’/ãƒšãƒ¼ã‚¸")

# ãƒ†ã‚¹ãƒˆæ¤œç´¢
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 6/6] ãƒ†ã‚¹ãƒˆæ¤œç´¢å®Ÿè¡Œ...")

test_queries = [
    "æ±æ—¥æœ¬å¤§éœ‡ç½ã®æ•™è¨“",
    "é¿é›£æ‰€ã®é‹å–¶",
    "ç½å®³å¯¾å¿œã®èª²é¡Œ",
    "å¾©æ—§å¾©èˆˆã®å–ã‚Šçµ„ã¿",
    "é˜²ç½å¯¾ç­–"
]

print(f"\næ¤œç´¢ã‚¯ã‚¨ãƒª: {len(test_queries)}å€‹")

import numpy as np

for query_text in test_queries:
    print(f"\nğŸ” ã‚¯ã‚¨ãƒª: ã€Œ{query_text}ã€")
    
    # ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    with torch.no_grad():
        query_embedding = visual_raptor.colbert_encoder.encode_text([query_text])
        query_np = query_embedding.detach().cpu().numpy()
    
    # é¡ä¼¼åº¦è¨ˆç®—
    similarities = []
    for i, encoded_doc in enumerate(encoded_docs):
        doc_np = encoded_doc['embedding'].numpy()
        
        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
        query_norm = query_np / (np.linalg.norm(query_np) + 1e-8)
        doc_norm = doc_np / (np.linalg.norm(doc_np) + 1e-8)
        sim = np.dot(query_norm.flatten(), doc_norm.flatten())
        
        similarities.append((i, sim))
    
    # Top-3å–å¾—
    similarities.sort(key=lambda x: x[1], reverse=True)
    top_3 = similarities[:3]
    
    print("  ğŸ“Š Top 3 çµæœ:")
    for rank, (doc_idx, sim) in enumerate(top_3, 1):
        metadata = encoded_docs[doc_idx]['metadata']
        print(f"    {rank}. [é¡ä¼¼åº¦: {sim:.4f}]")
        print(f"       PDF: {metadata['pdf_name']}")
        print(f"       ãƒšãƒ¼ã‚¸: {metadata['page_number']}/{metadata['total_pages']}")
        print(f"       ç”»åƒ: {Path(metadata['image_path']).name}")
        
        # OCRãƒ†ã‚­ã‚¹ãƒˆã®ä¸€éƒ¨ã‚’è¡¨ç¤º
        ocr_preview = metadata['ocr_text'][:100].replace('\n', ' ')
        if ocr_preview:
            print(f"       å†…å®¹: {ocr_preview}...")

# ã‚µãƒãƒªãƒ¼
print("\n" + "=" * 80)
print("ğŸ“Š å‡¦ç†ã‚µãƒãƒªãƒ¼")
print("=" * 80)
print(f"å‡¦ç†PDFãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(pdf_files)}")
for pdf_file in pdf_files:
    pdf_pages = [m for m in doc_metadata if m['pdf_name'] == pdf_file.name]
    print(f"  - {pdf_file.name}: {len(pdf_pages)}ãƒšãƒ¼ã‚¸")

print(f"\nç·ãƒšãƒ¼ã‚¸æ•°: {len(doc_metadata)}")
print(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æˆåŠŸ: {len(encoded_docs)}ãƒšãƒ¼ã‚¸")
print(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ™‚é–“: {encoding_time:.2f}ç§’")
print(f"å¹³å‡ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰é€Ÿåº¦: {encoding_time/len(encoded_docs):.3f}ç§’/ãƒšãƒ¼ã‚¸")
print(f"\nä½¿ç”¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼: ColModernVBERT (SigLIP)")
print(f"åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ: 768")
print(f"GPUä½¿ç”¨: {visual_raptor.colbert_encoder.device}")

print(f"\nğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª:")
print(f"  ç”»åƒ: {images_dir}")
print(f"  ç·ç”»åƒæ•°: {len(list(images_dir.glob('*.png')))}æš")

print("\n" + "=" * 80)
print("âœ… PDFç½å®³æ–‡æ›¸å‡¦ç†å®Œäº†ï¼")
print("=" * 80)

print("\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
print("  1. data/processed_pdfs/images/ ã§ç”Ÿæˆç”»åƒã‚’ç¢ºèª")
print("  2. æ¤œç´¢çµæœã‚’ç¢ºèªã—ã¦ç²¾åº¦ã‚’è©•ä¾¡")
print("  3. ã‚ˆã‚Šå¤šãã®ã‚¯ã‚¨ãƒªã§ãƒ†ã‚¹ãƒˆ")
print("  4. ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„æœ€é©åŒ–ã‚’æ¤œè¨")
